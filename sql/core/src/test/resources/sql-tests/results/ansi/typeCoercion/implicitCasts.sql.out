-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 585


-- !query 0
CREATE TABLE srcTestTable(
  byteVal byte,
  shortVal short,
  intVal int,
  longVal long,
  doubleVal double,
  floatVal float,
  decimal3_0Val decimal(3, 0),
  decimal5_0Val decimal(5, 0),
  decimal10_0Val decimal(10, 0),
  decimal10_2Val decimal(10, 2),
  decimal20_0Val decimal(20, 0),
  decimal30_15Val decimal(30, 15),
  decimal14_7Val decimal(14, 7),
  binaryVal binary,
  booleanVal boolean,
  stringVal string,
  dateVal date,
  timestampVal timestamp,
  arrayIntVal array<int>,
  arrayDoubleVal array<double>,
  mapStringIntVal map<string, int>,
  mapStringDoubleVal map<string, double>,
  structIntDoubleVal struct<d0: int, d1: double>,
  structStringIntVal struct<d0: string, d1: int>
) USING parquet
-- !query 0 schema
struct<>
-- !query 0 output



-- !query 1
INSERT INTO srcTestTable VALUES(
  1, 1, 1, 1, 1.0, 1.0, 1, 1, 1, 1.0, 1.0, 1.0, 1.0, 'abc', true, 'abc', '1970-01-01', '1970-01-01 00:00:00',
  array(1, 2, 3), array(1.0, 2.0, 3.0), map('k1', 1, 'k2', 2), map('k1', 1.0, 'k2', 2.0),
  struct(1, 1.0), struct('a', 1)
)
-- !query 1 schema
struct<>
-- !query 1 output



-- !query 2
INSERT INTO srcTestTable VALUES(
  127, 32767, 2147483647, 9223372036854775807, 1.797693e+308, 3.402823e+38,
  999, 99999, 9999999999, 99999.99, 9999999999999999999, 999999999999999.999999999999999, 9999999.9999999,
  'def', false, 'def', '2018-07-06', '2018-07-06 00:00:00',
  array(4, 5, 6), array(4.0, 5.0, 6.0), map('k3', 3, 'k4', 4), map('k3', 3.0, 'k4', 4.0),
  struct(2, 2.0), struct('b', 2)
)
-- !query 2 schema
struct<>
-- !query 2 output



-- !query 3
SELECT * FROM srcTestTable
-- !query 3 schema
struct<byteVal:tinyint,shortVal:smallint,intVal:int,longVal:bigint,doubleVal:double,floatVal:float,decimal3_0Val:decimal(3,0),decimal5_0Val:decimal(5,0),decimal10_0Val:decimal(10,0),decimal10_2Val:decimal(10,2),decimal20_0Val:decimal(20,0),decimal30_15Val:decimal(30,15),decimal14_7Val:decimal(14,7),binaryVal:binary,booleanVal:boolean,stringVal:string,dateVal:date,timestampVal:timestamp,arrayIntVal:array<int>,arrayDoubleVal:array<double>,mapStringIntVal:map<string,int>,mapStringDoubleVal:map<string,double>,structIntDoubleVal:struct<d0:int,d1:double>,structStringIntVal:struct<d0:string,d1:int>>
-- !query 3 output
1	1	1	1	1.0	1.0	1	1	1	1	1	1	1	abc	true	abc	1970-01-01	1970-01-01 00:00:00	[1,2,3]	[1.0,2.0,3.0]	{"k1":1,"k2":2}	{"k1":1.0,"k2":2.0}	{"d0":1,"d1":1.0}	{"d0":"a","d1":1}
127	32767	2147483647	9223372036854775807	1.797693E308	3.402823E38	999	99999	9999999999	99999.99	9999999999999999999	999999999999999.999999999999999	9999999.9999999	def	false	def	2018-07-06	2018-07-06 00:00:00	[4,5,6]	[4.0,5.0,6.0]	{"k3":3,"k4":4}	{"k3":3.0,"k4":4.0}	{"d0":2,"d1":2.0}	{"d0":"b","d1":2}


-- !query 4
SET spark.sql.ansi.typeCoercion.enabled=true
-- !query 4 schema
struct<key:string,value:string>
-- !query 4 output
spark.sql.ansi.typeCoercion.enabled	true


-- !query 5
SELECT shortVal * intVal FROM srcTestTable WHERE shortVal = 1
-- !query 5 schema
struct<(CAST(shortVal AS INT) * intVal):int>
-- !query 5 output
1


-- !query 6
SELECT shortVal * longVal FROM srcTestTable WHERE shortVal = 1
-- !query 6 schema
struct<(CAST(shortVal AS BIGINT) * longVal):bigint>
-- !query 6 output
1


-- !query 7
SELECT shortVal * doubleVal FROM srcTestTable WHERE shortVal = 1
-- !query 7 schema
struct<(CAST(shortVal AS DOUBLE) * doubleVal):double>
-- !query 7 output
1.0


-- !query 8
SELECT shortVal * floatVal FROM srcTestTable WHERE shortVal = 1
-- !query 8 schema
struct<(CAST(shortVal AS DOUBLE) * CAST(floatVal AS DOUBLE)):double>
-- !query 8 output
1.0


-- !query 9
SELECT shortVal * decimal3_0Val FROM srcTestTable WHERE shortVal = 1
-- !query 9 schema
struct<(CAST(CAST(shortVal AS DECIMAL(5,0)) AS DECIMAL(5,0)) * CAST(decimal3_0Val AS DECIMAL(5,0))):decimal(9,0)>
-- !query 9 output
1


-- !query 10
SELECT shortVal * decimal5_0Val FROM srcTestTable WHERE shortVal = 1
-- !query 10 schema
struct<(CAST(shortVal AS DECIMAL(5,0)) * decimal5_0Val):decimal(11,0)>
-- !query 10 output
1


-- !query 11
SELECT shortVal * decimal10_0Val FROM srcTestTable WHERE shortVal = 1
-- !query 11 schema
struct<(CAST(CAST(shortVal AS DECIMAL(5,0)) AS DECIMAL(10,0)) * CAST(decimal10_0Val AS DECIMAL(10,0))):decimal(16,0)>
-- !query 11 output
1


-- !query 12
SELECT shortVal * decimal10_2Val FROM srcTestTable WHERE shortVal = 1
-- !query 12 schema
struct<(CAST(CAST(shortVal AS DECIMAL(5,0)) AS DECIMAL(10,2)) * CAST(decimal10_2Val AS DECIMAL(10,2))):decimal(16,2)>
-- !query 12 output
1


-- !query 13
SELECT shortVal * decimal20_0Val FROM srcTestTable WHERE shortVal = 1
-- !query 13 schema
struct<(CAST(CAST(shortVal AS DECIMAL(5,0)) AS DECIMAL(20,0)) * CAST(decimal20_0Val AS DECIMAL(20,0))):decimal(26,0)>
-- !query 13 output
1


-- !query 14
SELECT shortVal * decimal30_15Val FROM srcTestTable WHERE shortVal = 1
-- !query 14 schema
struct<(CAST(CAST(shortVal AS DECIMAL(5,0)) AS DECIMAL(30,15)) * CAST(decimal30_15Val AS DECIMAL(30,15))):decimal(36,15)>
-- !query 14 output
1


-- !query 15
SELECT shortVal * decimal14_7Val FROM srcTestTable WHERE shortVal = 1
-- !query 15 schema
struct<(CAST(CAST(shortVal AS DECIMAL(5,0)) AS DECIMAL(14,7)) * CAST(decimal14_7Val AS DECIMAL(14,7))):decimal(20,7)>
-- !query 15 output
1


-- !query 16
SELECT intVal * longVal FROM srcTestTable WHERE intVal = 1
-- !query 16 schema
struct<(CAST(intVal AS BIGINT) * longVal):bigint>
-- !query 16 output
1


-- !query 17
SELECT intVal * doubleVal FROM srcTestTable WHERE intVal = 1
-- !query 17 schema
struct<(CAST(intVal AS DOUBLE) * doubleVal):double>
-- !query 17 output
1.0


-- !query 18
SELECT intVal * floatVal FROM srcTestTable WHERE intVal = 1
-- !query 18 schema
struct<(CAST(intVal AS DOUBLE) * CAST(floatVal AS DOUBLE)):double>
-- !query 18 output
1.0


-- !query 19
SELECT intVal * decimal3_0Val FROM srcTestTable WHERE intVal = 1
-- !query 19 schema
struct<(CAST(CAST(intVal AS DECIMAL(10,0)) AS DECIMAL(10,0)) * CAST(decimal3_0Val AS DECIMAL(10,0))):decimal(14,0)>
-- !query 19 output
1


-- !query 20
SELECT intVal * decimal5_0Val FROM srcTestTable WHERE intVal = 1
-- !query 20 schema
struct<(CAST(CAST(intVal AS DECIMAL(10,0)) AS DECIMAL(10,0)) * CAST(decimal5_0Val AS DECIMAL(10,0))):decimal(16,0)>
-- !query 20 output
1


-- !query 21
SELECT intVal * decimal10_0Val FROM srcTestTable WHERE intVal = 1
-- !query 21 schema
struct<(CAST(intVal AS DECIMAL(10,0)) * decimal10_0Val):decimal(21,0)>
-- !query 21 output
1


-- !query 22
SELECT intVal * decimal10_2Val FROM srcTestTable WHERE intVal = 1
-- !query 22 schema
struct<(CAST(CAST(intVal AS DECIMAL(10,0)) AS DECIMAL(12,2)) * CAST(decimal10_2Val AS DECIMAL(12,2))):decimal(21,2)>
-- !query 22 output
1


-- !query 23
SELECT intVal * decimal20_0Val FROM srcTestTable WHERE intVal = 1
-- !query 23 schema
struct<(CAST(CAST(intVal AS DECIMAL(10,0)) AS DECIMAL(20,0)) * CAST(decimal20_0Val AS DECIMAL(20,0))):decimal(31,0)>
-- !query 23 output
1


-- !query 24
SELECT intVal * decimal30_15Val FROM srcTestTable WHERE intVal = 1
-- !query 24 schema
struct<(CAST(CAST(intVal AS DECIMAL(10,0)) AS DECIMAL(30,15)) * CAST(decimal30_15Val AS DECIMAL(30,15))):decimal(38,12)>
-- !query 24 output
1


-- !query 25
SELECT intVal * decimal14_7Val FROM srcTestTable WHERE intVal = 1
-- !query 25 schema
struct<(CAST(CAST(intVal AS DECIMAL(10,0)) AS DECIMAL(17,7)) * CAST(decimal14_7Val AS DECIMAL(17,7))):decimal(25,7)>
-- !query 25 output
1


-- !query 26
SELECT longVal * doubleVal FROM srcTestTable WHERE longVal = 1
-- !query 26 schema
struct<(CAST(longVal AS DOUBLE) * doubleVal):double>
-- !query 26 output
1.0


-- !query 27
SELECT longVal * floatVal FROM srcTestTable WHERE longVal = 1
-- !query 27 schema
struct<(CAST(longVal AS DOUBLE) * CAST(floatVal AS DOUBLE)):double>
-- !query 27 output
1.0


-- !query 28
SELECT longVal * decimal3_0Val FROM srcTestTable WHERE longVal = 1
-- !query 28 schema
struct<(CAST(CAST(longVal AS DECIMAL(20,0)) AS DECIMAL(20,0)) * CAST(decimal3_0Val AS DECIMAL(20,0))):decimal(24,0)>
-- !query 28 output
1


-- !query 29
SELECT longVal * decimal5_0Val FROM srcTestTable WHERE longVal = 1
-- !query 29 schema
struct<(CAST(CAST(longVal AS DECIMAL(20,0)) AS DECIMAL(20,0)) * CAST(decimal5_0Val AS DECIMAL(20,0))):decimal(26,0)>
-- !query 29 output
1


-- !query 30
SELECT longVal * decimal10_0Val FROM srcTestTable WHERE longVal = 1
-- !query 30 schema
struct<(CAST(CAST(longVal AS DECIMAL(20,0)) AS DECIMAL(20,0)) * CAST(decimal10_0Val AS DECIMAL(20,0))):decimal(31,0)>
-- !query 30 output
1


-- !query 31
SELECT longVal * decimal10_2Val FROM srcTestTable WHERE longVal = 1
-- !query 31 schema
struct<(CAST(CAST(longVal AS DECIMAL(20,0)) AS DECIMAL(22,2)) * CAST(decimal10_2Val AS DECIMAL(22,2))):decimal(31,2)>
-- !query 31 output
1


-- !query 32
SELECT longVal * decimal20_0Val FROM srcTestTable WHERE longVal = 1
-- !query 32 schema
struct<(CAST(longVal AS DECIMAL(20,0)) * decimal20_0Val):decimal(38,0)>
-- !query 32 output
1


-- !query 33
SELECT longVal * decimal30_15Val FROM srcTestTable WHERE longVal = 1
-- !query 33 schema
struct<(CAST(CAST(longVal AS DECIMAL(20,0)) AS DECIMAL(35,15)) * CAST(decimal30_15Val AS DECIMAL(35,15))):decimal(38,6)>
-- !query 33 output
1


-- !query 34
SELECT longVal * decimal14_7Val FROM srcTestTable WHERE longVal = 1
-- !query 34 schema
struct<(CAST(CAST(longVal AS DECIMAL(20,0)) AS DECIMAL(27,7)) * CAST(decimal14_7Val AS DECIMAL(27,7))):decimal(35,7)>
-- !query 34 output
1


-- !query 35
SELECT doubleVal * floatVal FROM srcTestTable WHERE doubleVal < 1.1
-- !query 35 schema
struct<(doubleVal * CAST(floatVal AS DOUBLE)):double>
-- !query 35 output
1.0


-- !query 36
SELECT doubleVal * decimal3_0Val FROM srcTestTable WHERE doubleVal < 1.1
-- !query 36 schema
struct<(doubleVal * CAST(decimal3_0Val AS DOUBLE)):double>
-- !query 36 output
1.0


-- !query 37
SELECT doubleVal * decimal5_0Val FROM srcTestTable WHERE doubleVal < 1.1
-- !query 37 schema
struct<(doubleVal * CAST(decimal5_0Val AS DOUBLE)):double>
-- !query 37 output
1.0


-- !query 38
SELECT doubleVal * decimal10_0Val FROM srcTestTable WHERE doubleVal < 1.1
-- !query 38 schema
struct<(doubleVal * CAST(decimal10_0Val AS DOUBLE)):double>
-- !query 38 output
1.0


-- !query 39
SELECT doubleVal * decimal10_2Val FROM srcTestTable WHERE doubleVal < 1.1
-- !query 39 schema
struct<(doubleVal * CAST(decimal10_2Val AS DOUBLE)):double>
-- !query 39 output
1.0


-- !query 40
SELECT doubleVal * decimal20_0Val FROM srcTestTable WHERE doubleVal < 1.1
-- !query 40 schema
struct<(doubleVal * CAST(decimal20_0Val AS DOUBLE)):double>
-- !query 40 output
1.0


-- !query 41
SELECT doubleVal * decimal30_15Val FROM srcTestTable WHERE doubleVal < 1.1
-- !query 41 schema
struct<(doubleVal * CAST(decimal30_15Val AS DOUBLE)):double>
-- !query 41 output
1.0


-- !query 42
SELECT doubleVal * decimal14_7Val FROM srcTestTable WHERE doubleVal < 1.1
-- !query 42 schema
struct<(doubleVal * CAST(decimal14_7Val AS DOUBLE)):double>
-- !query 42 output
1.0


-- !query 43
SELECT floatVal * decimal3_0Val FROM srcTestTable WHERE floatVal < 1.1
-- !query 43 schema
struct<(CAST(floatVal AS DOUBLE) * CAST(decimal3_0Val AS DOUBLE)):double>
-- !query 43 output
1.0


-- !query 44
SELECT floatVal * decimal5_0Val FROM srcTestTable WHERE floatVal < 1.1
-- !query 44 schema
struct<(CAST(floatVal AS DOUBLE) * CAST(decimal5_0Val AS DOUBLE)):double>
-- !query 44 output
1.0


-- !query 45
SELECT floatVal * decimal10_0Val FROM srcTestTable WHERE floatVal < 1.1
-- !query 45 schema
struct<(CAST(floatVal AS DOUBLE) * CAST(decimal10_0Val AS DOUBLE)):double>
-- !query 45 output
1.0


-- !query 46
SELECT floatVal * decimal10_2Val FROM srcTestTable WHERE floatVal < 1.1
-- !query 46 schema
struct<(CAST(floatVal AS DOUBLE) * CAST(decimal10_2Val AS DOUBLE)):double>
-- !query 46 output
1.0


-- !query 47
SELECT floatVal * decimal20_0Val FROM srcTestTable WHERE floatVal < 1.1
-- !query 47 schema
struct<(CAST(floatVal AS DOUBLE) * CAST(decimal20_0Val AS DOUBLE)):double>
-- !query 47 output
1.0


-- !query 48
SELECT floatVal * decimal30_15Val FROM srcTestTable WHERE floatVal < 1.1
-- !query 48 schema
struct<(CAST(floatVal AS DOUBLE) * CAST(decimal30_15Val AS DOUBLE)):double>
-- !query 48 output
1.0


-- !query 49
SELECT floatVal * decimal14_7Val FROM srcTestTable WHERE floatVal < 1.1
-- !query 49 schema
struct<(CAST(floatVal AS DOUBLE) * CAST(decimal14_7Val AS DOUBLE)):double>
-- !query 49 output
1.0


-- !query 50
SELECT decimal3_0Val * decimal5_0Val FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 50 schema
struct<(CAST(decimal3_0Val AS DECIMAL(5,0)) * CAST(decimal5_0Val AS DECIMAL(5,0))):decimal(9,0)>
-- !query 50 output
1


-- !query 51
SELECT decimal3_0Val * decimal10_0Val FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 51 schema
struct<(CAST(decimal3_0Val AS DECIMAL(10,0)) * CAST(decimal10_0Val AS DECIMAL(10,0))):decimal(14,0)>
-- !query 51 output
1


-- !query 52
SELECT decimal3_0Val * decimal10_2Val FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 52 schema
struct<(CAST(decimal3_0Val AS DECIMAL(10,2)) * CAST(decimal10_2Val AS DECIMAL(10,2))):decimal(14,2)>
-- !query 52 output
1


-- !query 53
SELECT decimal3_0Val * decimal20_0Val FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 53 schema
struct<(CAST(decimal3_0Val AS DECIMAL(20,0)) * CAST(decimal20_0Val AS DECIMAL(20,0))):decimal(24,0)>
-- !query 53 output
1


-- !query 54
SELECT decimal3_0Val * decimal30_15Val FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 54 schema
struct<(CAST(decimal3_0Val AS DECIMAL(30,15)) * CAST(decimal30_15Val AS DECIMAL(30,15))):decimal(34,15)>
-- !query 54 output
1


-- !query 55
SELECT decimal3_0Val * decimal14_7Val FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 55 schema
struct<(CAST(decimal3_0Val AS DECIMAL(14,7)) * CAST(decimal14_7Val AS DECIMAL(14,7))):decimal(18,7)>
-- !query 55 output
1


-- !query 56
SELECT decimal5_0Val * decimal10_0Val FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 56 schema
struct<(CAST(decimal5_0Val AS DECIMAL(10,0)) * CAST(decimal10_0Val AS DECIMAL(10,0))):decimal(16,0)>
-- !query 56 output
1


-- !query 57
SELECT decimal5_0Val * decimal10_2Val FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 57 schema
struct<(CAST(decimal5_0Val AS DECIMAL(10,2)) * CAST(decimal10_2Val AS DECIMAL(10,2))):decimal(16,2)>
-- !query 57 output
1


-- !query 58
SELECT decimal5_0Val * decimal20_0Val FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 58 schema
struct<(CAST(decimal5_0Val AS DECIMAL(20,0)) * CAST(decimal20_0Val AS DECIMAL(20,0))):decimal(26,0)>
-- !query 58 output
1


-- !query 59
SELECT decimal5_0Val * decimal30_15Val FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 59 schema
struct<(CAST(decimal5_0Val AS DECIMAL(30,15)) * CAST(decimal30_15Val AS DECIMAL(30,15))):decimal(36,15)>
-- !query 59 output
1


-- !query 60
SELECT decimal5_0Val * decimal14_7Val FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 60 schema
struct<(CAST(decimal5_0Val AS DECIMAL(14,7)) * CAST(decimal14_7Val AS DECIMAL(14,7))):decimal(20,7)>
-- !query 60 output
1


-- !query 61
SELECT decimal10_0Val * decimal10_2Val FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 61 schema
struct<(CAST(decimal10_0Val AS DECIMAL(12,2)) * CAST(decimal10_2Val AS DECIMAL(12,2))):decimal(21,2)>
-- !query 61 output
1


-- !query 62
SELECT decimal10_0Val * decimal20_0Val FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 62 schema
struct<(CAST(decimal10_0Val AS DECIMAL(20,0)) * CAST(decimal20_0Val AS DECIMAL(20,0))):decimal(31,0)>
-- !query 62 output
1


-- !query 63
SELECT decimal10_0Val * decimal30_15Val FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 63 schema
struct<(CAST(decimal10_0Val AS DECIMAL(30,15)) * CAST(decimal30_15Val AS DECIMAL(30,15))):decimal(38,12)>
-- !query 63 output
1


-- !query 64
SELECT decimal10_0Val * decimal14_7Val FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 64 schema
struct<(CAST(decimal10_0Val AS DECIMAL(17,7)) * CAST(decimal14_7Val AS DECIMAL(17,7))):decimal(25,7)>
-- !query 64 output
1


-- !query 65
SELECT decimal10_2Val * decimal20_0Val FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 65 schema
struct<(CAST(decimal10_2Val AS DECIMAL(22,2)) * CAST(decimal20_0Val AS DECIMAL(22,2))):decimal(31,2)>
-- !query 65 output
1


-- !query 66
SELECT decimal10_2Val * decimal30_15Val FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 66 schema
struct<(CAST(decimal10_2Val AS DECIMAL(30,15)) * CAST(decimal30_15Val AS DECIMAL(30,15))):decimal(38,14)>
-- !query 66 output
1


-- !query 67
SELECT decimal10_2Val * decimal14_7Val FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 67 schema
struct<(CAST(decimal10_2Val AS DECIMAL(15,7)) * CAST(decimal14_7Val AS DECIMAL(15,7))):decimal(25,9)>
-- !query 67 output
1


-- !query 68
SELECT decimal30_15Val * decimal30_15Val FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 68 schema
struct<(decimal30_15Val * decimal30_15Val):decimal(38,7)>
-- !query 68 output
1


-- !query 69
SELECT decimal30_15Val * decimal14_7Val FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 69 schema
struct<(CAST(decimal30_15Val AS DECIMAL(30,15)) * CAST(decimal14_7Val AS DECIMAL(30,15))):decimal(38,15)>
-- !query 69 output
1


-- !query 70
SELECT binaryVal || shortVal FROM srcTestTable LIMIT 1
-- !query 70 schema
struct<concat(CAST(binaryVal AS STRING), CAST(shortVal AS STRING)):string>
-- !query 70 output
def32767


-- !query 71
SELECT binaryVal || intVal FROM srcTestTable LIMIT 1
-- !query 71 schema
struct<concat(CAST(binaryVal AS STRING), CAST(intVal AS STRING)):string>
-- !query 71 output
def2147483647


-- !query 72
SELECT binaryVal || longVal FROM srcTestTable LIMIT 1
-- !query 72 schema
struct<concat(CAST(binaryVal AS STRING), CAST(longVal AS STRING)):string>
-- !query 72 output
def9223372036854775807


-- !query 73
SELECT binaryVal || doubleVal FROM srcTestTable LIMIT 1
-- !query 73 schema
struct<concat(CAST(binaryVal AS STRING), CAST(doubleVal AS STRING)):string>
-- !query 73 output
def1.797693E308


-- !query 74
SELECT binaryVal || floatVal FROM srcTestTable LIMIT 1
-- !query 74 schema
struct<concat(CAST(binaryVal AS STRING), CAST(floatVal AS STRING)):string>
-- !query 74 output
def3.402823E38


-- !query 75
SELECT binaryVal || decimal3_0Val FROM srcTestTable LIMIT 1
-- !query 75 schema
struct<concat(CAST(binaryVal AS STRING), CAST(decimal3_0Val AS STRING)):string>
-- !query 75 output
def999


-- !query 76
SELECT binaryVal || decimal5_0Val FROM srcTestTable LIMIT 1
-- !query 76 schema
struct<concat(CAST(binaryVal AS STRING), CAST(decimal5_0Val AS STRING)):string>
-- !query 76 output
def99999


-- !query 77
SELECT binaryVal || decimal10_0Val FROM srcTestTable LIMIT 1
-- !query 77 schema
struct<concat(CAST(binaryVal AS STRING), CAST(decimal10_0Val AS STRING)):string>
-- !query 77 output
def9999999999


-- !query 78
SELECT binaryVal || decimal10_2Val FROM srcTestTable LIMIT 1
-- !query 78 schema
struct<concat(CAST(binaryVal AS STRING), CAST(decimal10_2Val AS STRING)):string>
-- !query 78 output
def99999.99


-- !query 79
SELECT binaryVal || decimal20_0Val FROM srcTestTable LIMIT 1
-- !query 79 schema
struct<concat(CAST(binaryVal AS STRING), CAST(decimal20_0Val AS STRING)):string>
-- !query 79 output
def9999999999999999999


-- !query 80
SELECT binaryVal || decimal30_15Val FROM srcTestTable LIMIT 1
-- !query 80 schema
struct<concat(CAST(binaryVal AS STRING), CAST(decimal30_15Val AS STRING)):string>
-- !query 80 output
def999999999999999.999999999999999


-- !query 81
SELECT binaryVal || decimal14_7Val FROM srcTestTable LIMIT 1
-- !query 81 schema
struct<concat(CAST(binaryVal AS STRING), CAST(decimal14_7Val AS STRING)):string>
-- !query 81 output
def9999999.9999999


-- !query 82
SELECT binaryVal || booleanVal FROM srcTestTable LIMIT 1
-- !query 82 schema
struct<concat(CAST(binaryVal AS STRING), CAST(booleanVal AS STRING)):string>
-- !query 82 output
deffalse


-- !query 83
SELECT binaryVal || stringVal FROM srcTestTable LIMIT 1
-- !query 83 schema
struct<concat(CAST(binaryVal AS STRING), stringVal):string>
-- !query 83 output
defdef


-- !query 84
SELECT binaryVal || dateVal FROM srcTestTable LIMIT 1
-- !query 84 schema
struct<concat(CAST(binaryVal AS STRING), CAST(dateVal AS STRING)):string>
-- !query 84 output
def2018-07-06


-- !query 85
SELECT binaryVal || timestampVal FROM srcTestTable LIMIT 1
-- !query 85 schema
struct<concat(CAST(binaryVal AS STRING), CAST(timestampVal AS STRING)):string>
-- !query 85 output
def2018-07-06 00:00:00


-- !query 86
SELECT binaryVal || arrayIntVal FROM srcTestTable LIMIT 1
-- !query 86 schema
struct<>
-- !query 86 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(CAST(default.srctesttable.`binaryVal` AS STRING), default.srctesttable.`arrayIntVal`)' due to data type mismatch: input to function concat should all be the same type, but it's [string, array<int>]; line 1 pos 7


-- !query 87
SELECT binaryVal || arrayDoubleVal FROM srcTestTable LIMIT 1
-- !query 87 schema
struct<>
-- !query 87 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(CAST(default.srctesttable.`binaryVal` AS STRING), default.srctesttable.`arrayDoubleVal`)' due to data type mismatch: input to function concat should all be the same type, but it's [string, array<double>]; line 1 pos 7


-- !query 88
SELECT binaryVal || mapStringIntVal FROM srcTestTable LIMIT 1
-- !query 88 schema
struct<>
-- !query 88 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(CAST(default.srctesttable.`binaryVal` AS STRING), default.srctesttable.`mapStringIntVal`)' due to data type mismatch: input to function concat should have been string, binary or array, but it's [string, map<string,int>]; line 1 pos 7


-- !query 89
SELECT binaryVal || mapStringDoubleVal FROM srcTestTable LIMIT 1
-- !query 89 schema
struct<>
-- !query 89 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(CAST(default.srctesttable.`binaryVal` AS STRING), default.srctesttable.`mapStringDoubleVal`)' due to data type mismatch: input to function concat should have been string, binary or array, but it's [string, map<string,double>]; line 1 pos 7


-- !query 90
SELECT binaryVal || structIntDoubleVal FROM srcTestTable LIMIT 1
-- !query 90 schema
struct<>
-- !query 90 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(CAST(default.srctesttable.`binaryVal` AS STRING), default.srctesttable.`structIntDoubleVal`)' due to data type mismatch: input to function concat should have been string, binary or array, but it's [string, struct<d0:int,d1:double>]; line 1 pos 7


-- !query 91
SELECT binaryVal || structStringIntVal FROM srcTestTable LIMIT 1
-- !query 91 schema
struct<>
-- !query 91 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(CAST(default.srctesttable.`binaryVal` AS STRING), default.srctesttable.`structStringIntVal`)' due to data type mismatch: input to function concat should have been string, binary or array, but it's [string, struct<d0:string,d1:int>]; line 1 pos 7


-- !query 92
SELECT stringVal || shortVal FROM srcTestTable LIMIT 1
-- !query 92 schema
struct<concat(stringVal, CAST(shortVal AS STRING)):string>
-- !query 92 output
def32767


-- !query 93
SELECT stringVal || intVal FROM srcTestTable LIMIT 1
-- !query 93 schema
struct<concat(stringVal, CAST(intVal AS STRING)):string>
-- !query 93 output
def2147483647


-- !query 94
SELECT stringVal || longVal FROM srcTestTable LIMIT 1
-- !query 94 schema
struct<concat(stringVal, CAST(longVal AS STRING)):string>
-- !query 94 output
def9223372036854775807


-- !query 95
SELECT stringVal || doubleVal FROM srcTestTable LIMIT 1
-- !query 95 schema
struct<concat(stringVal, CAST(doubleVal AS STRING)):string>
-- !query 95 output
def1.797693E308


-- !query 96
SELECT stringVal || floatVal FROM srcTestTable LIMIT 1
-- !query 96 schema
struct<concat(stringVal, CAST(floatVal AS STRING)):string>
-- !query 96 output
def3.402823E38


-- !query 97
SELECT stringVal || decimal3_0Val FROM srcTestTable LIMIT 1
-- !query 97 schema
struct<concat(stringVal, CAST(decimal3_0Val AS STRING)):string>
-- !query 97 output
def999


-- !query 98
SELECT stringVal || decimal5_0Val FROM srcTestTable LIMIT 1
-- !query 98 schema
struct<concat(stringVal, CAST(decimal5_0Val AS STRING)):string>
-- !query 98 output
def99999


-- !query 99
SELECT stringVal || decimal10_0Val FROM srcTestTable LIMIT 1
-- !query 99 schema
struct<concat(stringVal, CAST(decimal10_0Val AS STRING)):string>
-- !query 99 output
def9999999999


-- !query 100
SELECT stringVal || decimal10_2Val FROM srcTestTable LIMIT 1
-- !query 100 schema
struct<concat(stringVal, CAST(decimal10_2Val AS STRING)):string>
-- !query 100 output
def99999.99


-- !query 101
SELECT stringVal || decimal20_0Val FROM srcTestTable LIMIT 1
-- !query 101 schema
struct<concat(stringVal, CAST(decimal20_0Val AS STRING)):string>
-- !query 101 output
def9999999999999999999


-- !query 102
SELECT stringVal || decimal30_15Val FROM srcTestTable LIMIT 1
-- !query 102 schema
struct<concat(stringVal, CAST(decimal30_15Val AS STRING)):string>
-- !query 102 output
def999999999999999.999999999999999


-- !query 103
SELECT stringVal || decimal14_7Val FROM srcTestTable LIMIT 1
-- !query 103 schema
struct<concat(stringVal, CAST(decimal14_7Val AS STRING)):string>
-- !query 103 output
def9999999.9999999


-- !query 104
SELECT stringVal || booleanVal FROM srcTestTable LIMIT 1
-- !query 104 schema
struct<concat(stringVal, CAST(booleanVal AS STRING)):string>
-- !query 104 output
deffalse


-- !query 105
SELECT stringVal || stringVal FROM srcTestTable LIMIT 1
-- !query 105 schema
struct<concat(stringVal, stringVal):string>
-- !query 105 output
defdef


-- !query 106
SELECT stringVal || dateVal FROM srcTestTable LIMIT 1
-- !query 106 schema
struct<concat(stringVal, CAST(dateVal AS STRING)):string>
-- !query 106 output
def2018-07-06


-- !query 107
SELECT stringVal || timestampVal FROM srcTestTable LIMIT 1
-- !query 107 schema
struct<concat(stringVal, CAST(timestampVal AS STRING)):string>
-- !query 107 output
def2018-07-06 00:00:00


-- !query 108
SELECT stringVal || arrayIntVal FROM srcTestTable LIMIT 1
-- !query 108 schema
struct<>
-- !query 108 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(default.srctesttable.`stringVal`, default.srctesttable.`arrayIntVal`)' due to data type mismatch: input to function concat should all be the same type, but it's [string, array<int>]; line 1 pos 7


-- !query 109
SELECT stringVal || arrayDoubleVal FROM srcTestTable LIMIT 1
-- !query 109 schema
struct<>
-- !query 109 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(default.srctesttable.`stringVal`, default.srctesttable.`arrayDoubleVal`)' due to data type mismatch: input to function concat should all be the same type, but it's [string, array<double>]; line 1 pos 7


-- !query 110
SELECT stringVal || mapStringIntVal FROM srcTestTable LIMIT 1
-- !query 110 schema
struct<>
-- !query 110 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(default.srctesttable.`stringVal`, default.srctesttable.`mapStringIntVal`)' due to data type mismatch: input to function concat should have been string, binary or array, but it's [string, map<string,int>]; line 1 pos 7


-- !query 111
SELECT stringVal || mapStringDoubleVal FROM srcTestTable LIMIT 1
-- !query 111 schema
struct<>
-- !query 111 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(default.srctesttable.`stringVal`, default.srctesttable.`mapStringDoubleVal`)' due to data type mismatch: input to function concat should have been string, binary or array, but it's [string, map<string,double>]; line 1 pos 7


-- !query 112
SELECT stringVal || structIntDoubleVal FROM srcTestTable LIMIT 1
-- !query 112 schema
struct<>
-- !query 112 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(default.srctesttable.`stringVal`, default.srctesttable.`structIntDoubleVal`)' due to data type mismatch: input to function concat should have been string, binary or array, but it's [string, struct<d0:int,d1:double>]; line 1 pos 7


-- !query 113
SELECT stringVal || structStringIntVal FROM srcTestTable LIMIT 1
-- !query 113 schema
struct<>
-- !query 113 output
org.apache.spark.sql.AnalysisException
cannot resolve 'concat(default.srctesttable.`stringVal`, default.srctesttable.`structStringIntVal`)' due to data type mismatch: input to function concat should have been string, binary or array, but it's [string, struct<d0:string,d1:int>]; line 1 pos 7


-- !query 114
SELECT shortIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 114 schema
struct<>
-- !query 114 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1690.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1690.0 (TID 45584, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (int) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 115
SELECT shortIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 115 schema
struct<>
-- !query 115 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1691.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1691.0 (TID 45586, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (bigint) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 116
SELECT shortIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 116 schema
struct<>
-- !query 116 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1692.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1692.0 (TID 45588, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (double) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 117
SELECT shortIn(floatVal) FROM srcTestTable WHERE floatVal < 1.1
-- !query 117 schema
struct<>
-- !query 117 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1693.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1693.0 (TID 45590, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (float) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 118
SELECT shortIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 118 schema
struct<>
-- !query 118 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1694.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1694.0 (TID 45592, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (decimal(3,0)) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 119
SELECT shortIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 119 schema
struct<>
-- !query 119 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1695.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1695.0 (TID 45594, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (decimal(5,0)) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 120
SELECT shortIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 120 schema
struct<>
-- !query 120 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1696.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1696.0 (TID 45596, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (decimal(10,0)) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 121
SELECT shortIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 121 schema
struct<>
-- !query 121 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1697.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1697.0 (TID 45598, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (decimal(10,2)) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 122
SELECT shortIn(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 122 schema
struct<>
-- !query 122 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1698.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1698.0 (TID 45600, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (decimal(20,0)) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 123
SELECT shortIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 123 schema
struct<>
-- !query 123 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1699.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1699.0 (TID 45602, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (decimal(30,15)) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 124
SELECT shortIn(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 124 schema
struct<>
-- !query 124 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1700.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1700.0 (TID 45604, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (decimal(14,7)) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 125
SELECT shortIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 125 schema
struct<>
-- !query 125 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1701.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1701.0 (TID 45605, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (binary) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 126
SELECT shortIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 126 schema
struct<>
-- !query 126 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1702.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1702.0 (TID 45606, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (boolean) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 127
SELECT shortIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 127 schema
struct<>
-- !query 127 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1703.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1703.0 (TID 45607, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (string) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 128
SELECT shortIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 128 schema
struct<>
-- !query 128 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1704.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1704.0 (TID 45608, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (date) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 129
SELECT shortIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 129 schema
struct<>
-- !query 129 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1705.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1705.0 (TID 45609, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (timestamp) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 130
SELECT shortIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 130 schema
struct<>
-- !query 130 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1706.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1706.0 (TID 45610, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (array<int>) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 131
SELECT shortIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 131 schema
struct<>
-- !query 131 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1707.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1707.0 (TID 45611, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (array<double>) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 132
SELECT shortIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 132 schema
struct<>
-- !query 132 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1708.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1708.0 (TID 45612, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (map<string,int>) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 133
SELECT shortIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 133 schema
struct<>
-- !query 133 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1709.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1709.0 (TID 45613, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (map<string,double>) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 134
SELECT shortIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 134 schema
struct<>
-- !query 134 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1710.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1710.0 (TID 45614, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (struct<d0:int,d1:double>) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 135
SELECT shortIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 135 schema
struct<>
-- !query 135 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1711.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1711.0 (TID 45615, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4896/1786201039: (struct<d0:string,d1:int>) => smallint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Short
	at scala.runtime.BoxesRunTime.unboxToShort(BoxesRunTime.java:99)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$2$adapted(SQLQueryTestSuite.scala:275)
	... 18 more

Driver stacktrace:


-- !query 136
SELECT shortIn(null)
-- !query 136 schema
struct<UDF:shortIn(null):smallint>
-- !query 136 output
NULL


-- !query 137
SELECT intIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 137 schema
struct<UDF:intIn(shortVal):int>
-- !query 137 output
1


-- !query 138
SELECT intIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 138 schema
struct<>
-- !query 138 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1714.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1714.0 (TID 45620, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (bigint) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 139
SELECT intIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 139 schema
struct<>
-- !query 139 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1715.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1715.0 (TID 45622, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (double) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 140
SELECT intIn(floatVal) FROM srcTestTable WHERE floatVal < 1.1
-- !query 140 schema
struct<>
-- !query 140 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1716.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1716.0 (TID 45624, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (float) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 141
SELECT intIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 141 schema
struct<>
-- !query 141 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1717.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1717.0 (TID 45626, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (decimal(3,0)) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 142
SELECT intIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 142 schema
struct<>
-- !query 142 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1718.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1718.0 (TID 45628, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (decimal(5,0)) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 143
SELECT intIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 143 schema
struct<>
-- !query 143 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1719.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1719.0 (TID 45630, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (decimal(10,0)) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 144
SELECT intIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 144 schema
struct<>
-- !query 144 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1720.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1720.0 (TID 45632, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (decimal(10,2)) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 145
SELECT intIn(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 145 schema
struct<>
-- !query 145 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1721.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1721.0 (TID 45634, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (decimal(20,0)) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 146
SELECT intIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 146 schema
struct<>
-- !query 146 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1722.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1722.0 (TID 45636, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (decimal(30,15)) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 147
SELECT intIn(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 147 schema
struct<>
-- !query 147 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1723.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1723.0 (TID 45638, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (decimal(14,7)) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 148
SELECT intIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 148 schema
struct<>
-- !query 148 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1724.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1724.0 (TID 45639, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (binary) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 149
SELECT intIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 149 schema
struct<>
-- !query 149 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1725.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1725.0 (TID 45640, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (boolean) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 150
SELECT intIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 150 schema
struct<>
-- !query 150 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1726.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1726.0 (TID 45641, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (string) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 151
SELECT intIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 151 schema
struct<>
-- !query 151 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1727.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1727.0 (TID 45642, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (date) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 152
SELECT intIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 152 schema
struct<>
-- !query 152 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1728.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1728.0 (TID 45643, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (timestamp) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 153
SELECT intIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 153 schema
struct<>
-- !query 153 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1729.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1729.0 (TID 45644, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (array<int>) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 154
SELECT intIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 154 schema
struct<>
-- !query 154 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1730.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1730.0 (TID 45645, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (array<double>) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 155
SELECT intIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 155 schema
struct<>
-- !query 155 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1731.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1731.0 (TID 45646, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (map<string,int>) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 156
SELECT intIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 156 schema
struct<>
-- !query 156 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1732.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1732.0 (TID 45647, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (map<string,double>) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 157
SELECT intIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 157 schema
struct<>
-- !query 157 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1733.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1733.0 (TID 45648, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (struct<d0:int,d1:double>) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 158
SELECT intIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 158 schema
struct<>
-- !query 158 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1734.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1734.0 (TID 45649, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4897/1059396506: (struct<d0:string,d1:int>) => int)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at scala.runtime.java8.JFunction1$mcII$sp.apply(JFunction1$mcII$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 159
SELECT intIn(null)
-- !query 159 schema
struct<UDF:intIn(null):int>
-- !query 159 output
NULL


-- !query 160
SELECT longIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 160 schema
struct<UDF:longIn(shortVal):bigint>
-- !query 160 output
1


-- !query 161
SELECT longIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 161 schema
struct<UDF:longIn(intVal):bigint>
-- !query 161 output
1


-- !query 162
SELECT longIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 162 schema
struct<>
-- !query 162 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1738.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1738.0 (TID 45656, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (double) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 163
SELECT longIn(floatVal) FROM srcTestTable WHERE floatVal < 1.1
-- !query 163 schema
struct<>
-- !query 163 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1739.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1739.0 (TID 45658, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (float) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 164
SELECT longIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 164 schema
struct<>
-- !query 164 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1740.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1740.0 (TID 45660, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (decimal(3,0)) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 165
SELECT longIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 165 schema
struct<>
-- !query 165 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1741.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1741.0 (TID 45662, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (decimal(5,0)) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 166
SELECT longIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 166 schema
struct<>
-- !query 166 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1742.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1742.0 (TID 45664, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (decimal(10,0)) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 167
SELECT longIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 167 schema
struct<>
-- !query 167 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1743.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1743.0 (TID 45666, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (decimal(10,2)) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 168
SELECT longIn(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 168 schema
struct<>
-- !query 168 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1744.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1744.0 (TID 45668, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (decimal(20,0)) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 169
SELECT longIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 169 schema
struct<>
-- !query 169 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1745.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1745.0 (TID 45670, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (decimal(30,15)) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 170
SELECT longIn(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 170 schema
struct<>
-- !query 170 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1746.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1746.0 (TID 45672, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (decimal(14,7)) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 171
SELECT longIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 171 schema
struct<>
-- !query 171 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1747.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1747.0 (TID 45673, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (binary) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 172
SELECT longIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 172 schema
struct<>
-- !query 172 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1748.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1748.0 (TID 45674, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (boolean) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 173
SELECT longIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 173 schema
struct<>
-- !query 173 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1749.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1749.0 (TID 45675, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (string) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 174
SELECT longIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 174 schema
struct<>
-- !query 174 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1750.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1750.0 (TID 45676, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (date) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 175
SELECT longIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 175 schema
struct<>
-- !query 175 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1751.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1751.0 (TID 45677, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (timestamp) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 176
SELECT longIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 176 schema
struct<>
-- !query 176 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1752.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1752.0 (TID 45678, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (array<int>) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 177
SELECT longIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 177 schema
struct<>
-- !query 177 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1753.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1753.0 (TID 45679, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (array<double>) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 178
SELECT longIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 178 schema
struct<>
-- !query 178 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1754.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1754.0 (TID 45680, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (map<string,int>) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 179
SELECT longIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 179 schema
struct<>
-- !query 179 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1755.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1755.0 (TID 45681, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (map<string,double>) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 180
SELECT longIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 180 schema
struct<>
-- !query 180 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1756.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1756.0 (TID 45682, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (struct<d0:int,d1:double>) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 181
SELECT longIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 181 schema
struct<>
-- !query 181 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1757.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1757.0 (TID 45683, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4898/1058834602: (struct<d0:string,d1:int>) => bigint)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Long
	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 182
SELECT longIn(null)
-- !query 182 schema
struct<UDF:longIn(null):bigint>
-- !query 182 output
NULL


-- !query 183
SELECT doubleIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 183 schema
struct<UDF:doubleIn(shortVal):double>
-- !query 183 output
1.0


-- !query 184
SELECT doubleIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 184 schema
struct<UDF:doubleIn(intVal):double>
-- !query 184 output
1.0


-- !query 185
SELECT doubleIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 185 schema
struct<UDF:doubleIn(longVal):double>
-- !query 185 output
1.0


-- !query 186
SELECT doubleIn(floatVal) FROM srcTestTable WHERE floatVal < 1.1
-- !query 186 schema
struct<UDF:doubleIn(floatVal):double>
-- !query 186 output
1.0


-- !query 187
SELECT doubleIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 187 schema
struct<UDF:doubleIn(decimal3_0Val):double>
-- !query 187 output
1.0


-- !query 188
SELECT doubleIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 188 schema
struct<UDF:doubleIn(decimal5_0Val):double>
-- !query 188 output
1.0


-- !query 189
SELECT doubleIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 189 schema
struct<UDF:doubleIn(decimal10_0Val):double>
-- !query 189 output
1.0


-- !query 190
SELECT doubleIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 190 schema
struct<UDF:doubleIn(decimal10_2Val):double>
-- !query 190 output
1.0


-- !query 191
SELECT doubleIn(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 191 schema
struct<UDF:doubleIn(decimal20_0Val):double>
-- !query 191 output
1.0


-- !query 192
SELECT doubleIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 192 schema
struct<UDF:doubleIn(decimal30_15Val):double>
-- !query 192 output
1.0


-- !query 193
SELECT doubleIn(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 193 schema
struct<UDF:doubleIn(decimal14_7Val):double>
-- !query 193 output
1.0


-- !query 194
SELECT doubleIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 194 schema
struct<>
-- !query 194 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1770.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1770.0 (TID 45707, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (binary) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 195
SELECT doubleIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 195 schema
struct<>
-- !query 195 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1771.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1771.0 (TID 45708, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (boolean) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 196
SELECT doubleIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 196 schema
struct<>
-- !query 196 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1772.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1772.0 (TID 45709, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (string) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 197
SELECT doubleIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 197 schema
struct<>
-- !query 197 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1773.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1773.0 (TID 45710, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (date) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 198
SELECT doubleIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 198 schema
struct<>
-- !query 198 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1774.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1774.0 (TID 45711, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (timestamp) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 199
SELECT doubleIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 199 schema
struct<>
-- !query 199 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1775.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1775.0 (TID 45712, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (array<int>) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 200
SELECT doubleIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 200 schema
struct<>
-- !query 200 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1776.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1776.0 (TID 45713, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (array<double>) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 201
SELECT doubleIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 201 schema
struct<>
-- !query 201 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1777.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1777.0 (TID 45714, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (map<string,int>) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 202
SELECT doubleIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 202 schema
struct<>
-- !query 202 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1778.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1778.0 (TID 45715, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (map<string,double>) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 203
SELECT doubleIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 203 schema
struct<>
-- !query 203 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1779.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1779.0 (TID 45716, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (struct<d0:int,d1:double>) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 204
SELECT doubleIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 204 schema
struct<>
-- !query 204 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1780.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1780.0 (TID 45717, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4899/2033429932: (struct<d0:string,d1:int>) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at scala.runtime.java8.JFunction1$mcDD$sp.apply(JFunction1$mcDD$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 205
SELECT doubleIn(null)
-- !query 205 schema
struct<UDF:doubleIn(null):double>
-- !query 205 output
NULL


-- !query 206
SELECT floatIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 206 schema
struct<UDF:floatIn(shortVal):float>
-- !query 206 output
1.0


-- !query 207
SELECT floatIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 207 schema
struct<UDF:floatIn(intVal):float>
-- !query 207 output
1.0


-- !query 208
SELECT floatIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 208 schema
struct<UDF:floatIn(longVal):float>
-- !query 208 output
1.0


-- !query 209
SELECT floatIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 209 schema
struct<>
-- !query 209 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1785.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1785.0 (TID 45726, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (double) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 210
SELECT floatIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 210 schema
struct<UDF:floatIn(decimal3_0Val):float>
-- !query 210 output
1.0


-- !query 211
SELECT floatIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 211 schema
struct<UDF:floatIn(decimal5_0Val):float>
-- !query 211 output
1.0


-- !query 212
SELECT floatIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 212 schema
struct<UDF:floatIn(decimal10_0Val):float>
-- !query 212 output
1.0


-- !query 213
SELECT floatIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 213 schema
struct<UDF:floatIn(decimal10_2Val):float>
-- !query 213 output
1.0


-- !query 214
SELECT floatIn(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 214 schema
struct<UDF:floatIn(decimal20_0Val):float>
-- !query 214 output
1.0


-- !query 215
SELECT floatIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 215 schema
struct<UDF:floatIn(decimal30_15Val):float>
-- !query 215 output
1.0


-- !query 216
SELECT floatIn(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 216 schema
struct<UDF:floatIn(decimal14_7Val):float>
-- !query 216 output
1.0


-- !query 217
SELECT floatIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 217 schema
struct<>
-- !query 217 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1793.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1793.0 (TID 45741, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (binary) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 218
SELECT floatIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 218 schema
struct<>
-- !query 218 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1794.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1794.0 (TID 45742, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (boolean) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 219
SELECT floatIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 219 schema
struct<>
-- !query 219 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1795.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1795.0 (TID 45743, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (string) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 220
SELECT floatIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 220 schema
struct<>
-- !query 220 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1796.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1796.0 (TID 45744, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (date) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 221
SELECT floatIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 221 schema
struct<>
-- !query 221 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1797.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1797.0 (TID 45745, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (timestamp) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 222
SELECT floatIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 222 schema
struct<>
-- !query 222 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1798.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1798.0 (TID 45746, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (array<int>) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 223
SELECT floatIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 223 schema
struct<>
-- !query 223 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1799.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1799.0 (TID 45747, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (array<double>) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 224
SELECT floatIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 224 schema
struct<>
-- !query 224 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1800.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1800.0 (TID 45748, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (map<string,int>) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 225
SELECT floatIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 225 schema
struct<>
-- !query 225 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1801.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1801.0 (TID 45749, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (map<string,double>) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 226
SELECT floatIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 226 schema
struct<>
-- !query 226 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1802.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1802.0 (TID 45750, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (struct<d0:int,d1:double>) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 227
SELECT floatIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 227 schema
struct<>
-- !query 227 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1803.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1803.0 (TID 45751, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4900/569491191: (struct<d0:string,d1:int>) => float)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Float
	at scala.runtime.BoxesRunTime.unboxToFloat(BoxesRunTime.java:111)
	at scala.runtime.java8.JFunction1$mcFF$sp.apply(JFunction1$mcFF$sp.java:23)
	... 18 more

Driver stacktrace:


-- !query 228
SELECT floatIn(null)
-- !query 228 schema
struct<UDF:floatIn(null):float>
-- !query 228 output
NULL


-- !query 229
SELECT decimal3_0In(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 229 schema
struct<UDF(shortVal):decimal(3,0)>
-- !query 229 output
1


-- !query 230
SELECT decimal3_0In(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 230 schema
struct<UDF(intVal):decimal(3,0)>
-- !query 230 output
1


-- !query 231
SELECT decimal3_0In(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 231 schema
struct<UDF(longVal):decimal(3,0)>
-- !query 231 output
1


-- !query 232
SELECT decimal3_0In(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 232 schema
struct<>
-- !query 232 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1808.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1808.0 (TID 45760, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (double) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 233
SELECT decimal3_0In(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 233 schema
struct<>
-- !query 233 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1809.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1809.0 (TID 45762, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (float) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 234
SELECT decimal3_0In(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 234 schema
struct<UDF(decimal5_0Val):decimal(3,0)>
-- !query 234 output
1


-- !query 235
SELECT decimal3_0In(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 235 schema
struct<UDF(decimal10_0Val):decimal(3,0)>
-- !query 235 output
1


-- !query 236
SELECT decimal3_0In(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 236 schema
struct<UDF(decimal10_2Val):decimal(3,0)>
-- !query 236 output
1


-- !query 237
SELECT decimal3_0In(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 237 schema
struct<UDF(decimal20_0Val):decimal(3,0)>
-- !query 237 output
1


-- !query 238
SELECT decimal3_0In(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 238 schema
struct<UDF(decimal30_15Val):decimal(3,0)>
-- !query 238 output
1


-- !query 239
SELECT decimal3_0In(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 239 schema
struct<UDF(decimal14_7Val):decimal(3,0)>
-- !query 239 output
1


-- !query 240
SELECT decimal3_0In(binaryVal) FROM srcTestTable LIMIT 1
-- !query 240 schema
struct<>
-- !query 240 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1816.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1816.0 (TID 45775, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (binary) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 241
SELECT decimal3_0In(booleanVal) FROM srcTestTable LIMIT 1
-- !query 241 schema
struct<>
-- !query 241 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1817.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1817.0 (TID 45776, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (boolean) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 242
SELECT decimal3_0In(stringVal) FROM srcTestTable LIMIT 1
-- !query 242 schema
struct<>
-- !query 242 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1818.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1818.0 (TID 45777, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (string) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 243
SELECT decimal3_0In(dateVal) FROM srcTestTable LIMIT 1
-- !query 243 schema
struct<>
-- !query 243 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1819.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1819.0 (TID 45778, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (date) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 244
SELECT decimal3_0In(timestampVal) FROM srcTestTable LIMIT 1
-- !query 244 schema
struct<>
-- !query 244 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1820.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1820.0 (TID 45779, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (timestamp) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 245
SELECT decimal3_0In(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 245 schema
struct<>
-- !query 245 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1821.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1821.0 (TID 45780, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<int>) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 246
SELECT decimal3_0In(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 246 schema
struct<>
-- !query 246 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1822.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1822.0 (TID 45781, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<double>) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 247
SELECT decimal3_0In(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 247 schema
struct<>
-- !query 247 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1823.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1823.0 (TID 45782, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,int>) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 248
SELECT decimal3_0In(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 248 schema
struct<>
-- !query 248 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1824.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1824.0 (TID 45783, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,double>) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 249
SELECT decimal3_0In(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 249 schema
struct<>
-- !query 249 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1825.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1825.0 (TID 45784, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:int,d1:double>) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 250
SELECT decimal3_0In(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 250 schema
struct<>
-- !query 250 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1826.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1826.0 (TID 45785, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:string,d1:int>) => decimal(3,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 251
SELECT decimal3_0In(null)
-- !query 251 schema
struct<UDF(null):decimal(3,0)>
-- !query 251 output
NULL


-- !query 252
SELECT decimal5_0In(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 252 schema
struct<UDF(shortVal):decimal(5,0)>
-- !query 252 output
1


-- !query 253
SELECT decimal5_0In(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 253 schema
struct<UDF(intVal):decimal(5,0)>
-- !query 253 output
1


-- !query 254
SELECT decimal5_0In(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 254 schema
struct<UDF(longVal):decimal(5,0)>
-- !query 254 output
1


-- !query 255
SELECT decimal5_0In(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 255 schema
struct<>
-- !query 255 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1831.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1831.0 (TID 45794, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (double) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 256
SELECT decimal5_0In(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 256 schema
struct<>
-- !query 256 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1832.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1832.0 (TID 45796, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (float) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 257
SELECT decimal5_0In(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 257 schema
struct<UDF(decimal3_0Val):decimal(5,0)>
-- !query 257 output
1


-- !query 258
SELECT decimal5_0In(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 258 schema
struct<UDF(decimal10_0Val):decimal(5,0)>
-- !query 258 output
1


-- !query 259
SELECT decimal5_0In(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 259 schema
struct<UDF(decimal10_2Val):decimal(5,0)>
-- !query 259 output
1


-- !query 260
SELECT decimal5_0In(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 260 schema
struct<UDF(decimal20_0Val):decimal(5,0)>
-- !query 260 output
1


-- !query 261
SELECT decimal5_0In(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 261 schema
struct<UDF(decimal30_15Val):decimal(5,0)>
-- !query 261 output
1


-- !query 262
SELECT decimal5_0In(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 262 schema
struct<UDF(decimal14_7Val):decimal(5,0)>
-- !query 262 output
1


-- !query 263
SELECT decimal5_0In(binaryVal) FROM srcTestTable LIMIT 1
-- !query 263 schema
struct<>
-- !query 263 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1839.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1839.0 (TID 45809, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (binary) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 264
SELECT decimal5_0In(booleanVal) FROM srcTestTable LIMIT 1
-- !query 264 schema
struct<>
-- !query 264 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1840.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1840.0 (TID 45810, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (boolean) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 265
SELECT decimal5_0In(stringVal) FROM srcTestTable LIMIT 1
-- !query 265 schema
struct<>
-- !query 265 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1841.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1841.0 (TID 45811, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (string) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 266
SELECT decimal5_0In(dateVal) FROM srcTestTable LIMIT 1
-- !query 266 schema
struct<>
-- !query 266 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1842.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1842.0 (TID 45812, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (date) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 267
SELECT decimal5_0In(timestampVal) FROM srcTestTable LIMIT 1
-- !query 267 schema
struct<>
-- !query 267 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1843.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1843.0 (TID 45813, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (timestamp) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 268
SELECT decimal5_0In(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 268 schema
struct<>
-- !query 268 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1844.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1844.0 (TID 45814, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<int>) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 269
SELECT decimal5_0In(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 269 schema
struct<>
-- !query 269 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1845.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1845.0 (TID 45815, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<double>) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 270
SELECT decimal5_0In(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 270 schema
struct<>
-- !query 270 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1846.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1846.0 (TID 45816, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,int>) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 271
SELECT decimal5_0In(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 271 schema
struct<>
-- !query 271 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1847.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1847.0 (TID 45817, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,double>) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 272
SELECT decimal5_0In(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 272 schema
struct<>
-- !query 272 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1848.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1848.0 (TID 45818, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:int,d1:double>) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 273
SELECT decimal5_0In(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 273 schema
struct<>
-- !query 273 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1849.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1849.0 (TID 45819, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:string,d1:int>) => decimal(5,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 274
SELECT decimal5_0In(null)
-- !query 274 schema
struct<UDF(null):decimal(5,0)>
-- !query 274 output
NULL


-- !query 275
SELECT decimal10_0In(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 275 schema
struct<UDF(shortVal):decimal(10,0)>
-- !query 275 output
1


-- !query 276
SELECT decimal10_0In(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 276 schema
struct<UDF(intVal):decimal(10,0)>
-- !query 276 output
1


-- !query 277
SELECT decimal10_0In(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 277 schema
struct<UDF(longVal):decimal(10,0)>
-- !query 277 output
1


-- !query 278
SELECT decimal10_0In(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 278 schema
struct<>
-- !query 278 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1854.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1854.0 (TID 45828, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (double) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 279
SELECT decimal10_0In(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 279 schema
struct<>
-- !query 279 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1855.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1855.0 (TID 45830, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (float) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 280
SELECT decimal10_0In(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 280 schema
struct<UDF(decimal3_0Val):decimal(10,0)>
-- !query 280 output
1


-- !query 281
SELECT decimal10_0In(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 281 schema
struct<UDF(decimal5_0Val):decimal(10,0)>
-- !query 281 output
1


-- !query 282
SELECT decimal10_0In(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 282 schema
struct<UDF(decimal10_2Val):decimal(10,0)>
-- !query 282 output
1


-- !query 283
SELECT decimal10_0In(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 283 schema
struct<UDF(decimal20_0Val):decimal(10,0)>
-- !query 283 output
1


-- !query 284
SELECT decimal10_0In(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 284 schema
struct<UDF(decimal30_15Val):decimal(10,0)>
-- !query 284 output
1


-- !query 285
SELECT decimal10_0In(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 285 schema
struct<UDF(decimal14_7Val):decimal(10,0)>
-- !query 285 output
1


-- !query 286
SELECT decimal10_0In(binaryVal) FROM srcTestTable LIMIT 1
-- !query 286 schema
struct<>
-- !query 286 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1862.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1862.0 (TID 45843, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (binary) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 287
SELECT decimal10_0In(booleanVal) FROM srcTestTable LIMIT 1
-- !query 287 schema
struct<>
-- !query 287 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1863.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1863.0 (TID 45844, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (boolean) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 288
SELECT decimal10_0In(stringVal) FROM srcTestTable LIMIT 1
-- !query 288 schema
struct<>
-- !query 288 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1864.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1864.0 (TID 45845, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (string) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 289
SELECT decimal10_0In(dateVal) FROM srcTestTable LIMIT 1
-- !query 289 schema
struct<>
-- !query 289 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1865.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1865.0 (TID 45846, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (date) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 290
SELECT decimal10_0In(timestampVal) FROM srcTestTable LIMIT 1
-- !query 290 schema
struct<>
-- !query 290 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1866.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1866.0 (TID 45847, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (timestamp) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 291
SELECT decimal10_0In(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 291 schema
struct<>
-- !query 291 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1867.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1867.0 (TID 45848, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<int>) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 292
SELECT decimal10_0In(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 292 schema
struct<>
-- !query 292 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1868.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1868.0 (TID 45849, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<double>) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 293
SELECT decimal10_0In(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 293 schema
struct<>
-- !query 293 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1869.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1869.0 (TID 45850, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,int>) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 294
SELECT decimal10_0In(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 294 schema
struct<>
-- !query 294 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1870.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1870.0 (TID 45851, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,double>) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 295
SELECT decimal10_0In(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 295 schema
struct<>
-- !query 295 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1871.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1871.0 (TID 45852, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:int,d1:double>) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 296
SELECT decimal10_0In(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 296 schema
struct<>
-- !query 296 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1872.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1872.0 (TID 45853, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:string,d1:int>) => decimal(10,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 297
SELECT decimal10_0In(null)
-- !query 297 schema
struct<UDF(null):decimal(10,0)>
-- !query 297 output
NULL


-- !query 298
SELECT decimal10_2In(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 298 schema
struct<UDF(shortVal):decimal(10,2)>
-- !query 298 output
1


-- !query 299
SELECT decimal10_2In(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 299 schema
struct<UDF(intVal):decimal(10,2)>
-- !query 299 output
1


-- !query 300
SELECT decimal10_2In(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 300 schema
struct<UDF(longVal):decimal(10,2)>
-- !query 300 output
1


-- !query 301
SELECT decimal10_2In(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 301 schema
struct<>
-- !query 301 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1877.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1877.0 (TID 45862, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (double) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 302
SELECT decimal10_2In(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 302 schema
struct<>
-- !query 302 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1878.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1878.0 (TID 45864, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (float) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 303
SELECT decimal10_2In(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 303 schema
struct<UDF(decimal3_0Val):decimal(10,2)>
-- !query 303 output
1


-- !query 304
SELECT decimal10_2In(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 304 schema
struct<UDF(decimal5_0Val):decimal(10,2)>
-- !query 304 output
1


-- !query 305
SELECT decimal10_2In(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 305 schema
struct<UDF(decimal10_0Val):decimal(10,2)>
-- !query 305 output
1


-- !query 306
SELECT decimal10_2In(decimal20_0Val) FROM srcTestTable WHERE decimal20_0Val = 1
-- !query 306 schema
struct<UDF(decimal20_0Val):decimal(10,2)>
-- !query 306 output
1


-- !query 307
SELECT decimal10_2In(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 307 schema
struct<UDF(decimal30_15Val):decimal(10,2)>
-- !query 307 output
1


-- !query 308
SELECT decimal10_2In(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 308 schema
struct<UDF(decimal14_7Val):decimal(10,2)>
-- !query 308 output
1


-- !query 309
SELECT decimal10_2In(binaryVal) FROM srcTestTable LIMIT 1
-- !query 309 schema
struct<>
-- !query 309 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1885.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1885.0 (TID 45877, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (binary) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 310
SELECT decimal10_2In(booleanVal) FROM srcTestTable LIMIT 1
-- !query 310 schema
struct<>
-- !query 310 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1886.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1886.0 (TID 45878, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (boolean) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 311
SELECT decimal10_2In(stringVal) FROM srcTestTable LIMIT 1
-- !query 311 schema
struct<>
-- !query 311 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1887.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1887.0 (TID 45879, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (string) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 312
SELECT decimal10_2In(dateVal) FROM srcTestTable LIMIT 1
-- !query 312 schema
struct<>
-- !query 312 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1888.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1888.0 (TID 45880, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (date) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 313
SELECT decimal10_2In(timestampVal) FROM srcTestTable LIMIT 1
-- !query 313 schema
struct<>
-- !query 313 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1889.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1889.0 (TID 45881, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (timestamp) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 314
SELECT decimal10_2In(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 314 schema
struct<>
-- !query 314 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1890.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1890.0 (TID 45882, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<int>) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 315
SELECT decimal10_2In(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 315 schema
struct<>
-- !query 315 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1891.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1891.0 (TID 45883, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<double>) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 316
SELECT decimal10_2In(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 316 schema
struct<>
-- !query 316 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1892.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1892.0 (TID 45884, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,int>) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 317
SELECT decimal10_2In(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 317 schema
struct<>
-- !query 317 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1893.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1893.0 (TID 45885, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,double>) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 318
SELECT decimal10_2In(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 318 schema
struct<>
-- !query 318 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1894.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1894.0 (TID 45886, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:int,d1:double>) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 319
SELECT decimal10_2In(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 319 schema
struct<>
-- !query 319 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1895.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1895.0 (TID 45887, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:string,d1:int>) => decimal(10,2))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 320
SELECT decimal10_2In(null)
-- !query 320 schema
struct<UDF(null):decimal(10,2)>
-- !query 320 output
NULL


-- !query 321
SELECT decimal20_0In(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 321 schema
struct<UDF(shortVal):decimal(20,0)>
-- !query 321 output
1


-- !query 322
SELECT decimal20_0In(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 322 schema
struct<UDF(intVal):decimal(20,0)>
-- !query 322 output
1


-- !query 323
SELECT decimal20_0In(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 323 schema
struct<UDF(longVal):decimal(20,0)>
-- !query 323 output
1


-- !query 324
SELECT decimal20_0In(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 324 schema
struct<>
-- !query 324 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1900.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1900.0 (TID 45896, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (double) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 325
SELECT decimal20_0In(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 325 schema
struct<>
-- !query 325 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1901.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1901.0 (TID 45898, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (float) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 326
SELECT decimal20_0In(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 326 schema
struct<UDF(decimal3_0Val):decimal(20,0)>
-- !query 326 output
1


-- !query 327
SELECT decimal20_0In(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 327 schema
struct<UDF(decimal5_0Val):decimal(20,0)>
-- !query 327 output
1


-- !query 328
SELECT decimal20_0In(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 328 schema
struct<UDF(decimal10_0Val):decimal(20,0)>
-- !query 328 output
1


-- !query 329
SELECT decimal20_0In(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 329 schema
struct<UDF(decimal10_2Val):decimal(20,0)>
-- !query 329 output
1


-- !query 330
SELECT decimal20_0In(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 330 schema
struct<UDF(decimal30_15Val):decimal(20,0)>
-- !query 330 output
1


-- !query 331
SELECT decimal20_0In(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 331 schema
struct<UDF(decimal14_7Val):decimal(20,0)>
-- !query 331 output
1


-- !query 332
SELECT decimal20_0In(binaryVal) FROM srcTestTable LIMIT 1
-- !query 332 schema
struct<>
-- !query 332 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1908.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1908.0 (TID 45911, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (binary) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 333
SELECT decimal20_0In(booleanVal) FROM srcTestTable LIMIT 1
-- !query 333 schema
struct<>
-- !query 333 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1909.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1909.0 (TID 45912, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (boolean) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 334
SELECT decimal20_0In(stringVal) FROM srcTestTable LIMIT 1
-- !query 334 schema
struct<>
-- !query 334 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1910.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1910.0 (TID 45913, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (string) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 335
SELECT decimal20_0In(dateVal) FROM srcTestTable LIMIT 1
-- !query 335 schema
struct<>
-- !query 335 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1911.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1911.0 (TID 45914, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (date) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 336
SELECT decimal20_0In(timestampVal) FROM srcTestTable LIMIT 1
-- !query 336 schema
struct<>
-- !query 336 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1912.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1912.0 (TID 45915, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (timestamp) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 337
SELECT decimal20_0In(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 337 schema
struct<>
-- !query 337 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1913.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1913.0 (TID 45916, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<int>) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 338
SELECT decimal20_0In(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 338 schema
struct<>
-- !query 338 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1914.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1914.0 (TID 45917, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<double>) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 339
SELECT decimal20_0In(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 339 schema
struct<>
-- !query 339 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1915.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1915.0 (TID 45918, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,int>) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 340
SELECT decimal20_0In(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 340 schema
struct<>
-- !query 340 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1916.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1916.0 (TID 45919, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,double>) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 341
SELECT decimal20_0In(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 341 schema
struct<>
-- !query 341 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1917.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1917.0 (TID 45920, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:int,d1:double>) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 342
SELECT decimal20_0In(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 342 schema
struct<>
-- !query 342 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1918.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1918.0 (TID 45921, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:string,d1:int>) => decimal(20,0))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 343
SELECT decimal20_0In(null)
-- !query 343 schema
struct<UDF(null):decimal(20,0)>
-- !query 343 output
NULL


-- !query 344
SELECT decimal30_15In(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 344 schema
struct<UDF(shortVal):decimal(30,15)>
-- !query 344 output
1


-- !query 345
SELECT decimal30_15In(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 345 schema
struct<UDF(intVal):decimal(30,15)>
-- !query 345 output
1


-- !query 346
SELECT decimal30_15In(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 346 schema
struct<UDF(longVal):decimal(30,15)>
-- !query 346 output
1


-- !query 347
SELECT decimal30_15In(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 347 schema
struct<>
-- !query 347 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1923.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1923.0 (TID 45930, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (double) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 348
SELECT decimal30_15In(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 348 schema
struct<>
-- !query 348 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1924.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1924.0 (TID 45932, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (float) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 349
SELECT decimal30_15In(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 349 schema
struct<UDF(decimal3_0Val):decimal(30,15)>
-- !query 349 output
1


-- !query 350
SELECT decimal30_15In(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 350 schema
struct<UDF(decimal5_0Val):decimal(30,15)>
-- !query 350 output
1


-- !query 351
SELECT decimal30_15In(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 351 schema
struct<UDF(decimal10_0Val):decimal(30,15)>
-- !query 351 output
1


-- !query 352
SELECT decimal30_15In(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 352 schema
struct<UDF(decimal10_2Val):decimal(30,15)>
-- !query 352 output
1


-- !query 353
SELECT decimal30_15In(decimal14_7Val) FROM srcTestTable WHERE decimal14_7Val = 1
-- !query 353 schema
struct<UDF(decimal14_7Val):decimal(30,15)>
-- !query 353 output
1


-- !query 354
SELECT decimal30_15In(binaryVal) FROM srcTestTable LIMIT 1
-- !query 354 schema
struct<>
-- !query 354 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1930.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1930.0 (TID 45943, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (binary) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 355
SELECT decimal30_15In(booleanVal) FROM srcTestTable LIMIT 1
-- !query 355 schema
struct<>
-- !query 355 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1931.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1931.0 (TID 45944, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (boolean) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 356
SELECT decimal30_15In(stringVal) FROM srcTestTable LIMIT 1
-- !query 356 schema
struct<>
-- !query 356 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1932.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1932.0 (TID 45945, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (string) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 357
SELECT decimal30_15In(dateVal) FROM srcTestTable LIMIT 1
-- !query 357 schema
struct<>
-- !query 357 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1933.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1933.0 (TID 45946, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (date) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 358
SELECT decimal30_15In(timestampVal) FROM srcTestTable LIMIT 1
-- !query 358 schema
struct<>
-- !query 358 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1934.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1934.0 (TID 45947, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (timestamp) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 359
SELECT decimal30_15In(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 359 schema
struct<>
-- !query 359 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1935.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1935.0 (TID 45948, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<int>) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 360
SELECT decimal30_15In(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 360 schema
struct<>
-- !query 360 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1936.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1936.0 (TID 45949, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<double>) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 361
SELECT decimal30_15In(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 361 schema
struct<>
-- !query 361 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1937.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1937.0 (TID 45950, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,int>) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 362
SELECT decimal30_15In(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 362 schema
struct<>
-- !query 362 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1938.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1938.0 (TID 45951, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,double>) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 363
SELECT decimal30_15In(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 363 schema
struct<>
-- !query 363 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1939.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1939.0 (TID 45952, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:int,d1:double>) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 364
SELECT decimal30_15In(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 364 schema
struct<>
-- !query 364 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1940.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1940.0 (TID 45953, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:string,d1:int>) => decimal(30,15))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 365
SELECT decimal30_15In(null)
-- !query 365 schema
struct<UDF(null):decimal(30,15)>
-- !query 365 output
NULL


-- !query 366
SELECT decimal14_7In(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 366 schema
struct<UDF(shortVal):decimal(14,7)>
-- !query 366 output
1


-- !query 367
SELECT decimal14_7In(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 367 schema
struct<UDF(intVal):decimal(14,7)>
-- !query 367 output
1


-- !query 368
SELECT decimal14_7In(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 368 schema
struct<UDF(longVal):decimal(14,7)>
-- !query 368 output
1


-- !query 369
SELECT decimal14_7In(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 369 schema
struct<>
-- !query 369 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1945.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1945.0 (TID 45962, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (double) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 370
SELECT decimal14_7In(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 370 schema
struct<>
-- !query 370 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1946.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1946.0 (TID 45964, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (float) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 371
SELECT decimal14_7In(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 371 schema
struct<UDF(decimal3_0Val):decimal(14,7)>
-- !query 371 output
1


-- !query 372
SELECT decimal14_7In(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 372 schema
struct<UDF(decimal5_0Val):decimal(14,7)>
-- !query 372 output
1


-- !query 373
SELECT decimal14_7In(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 373 schema
struct<UDF(decimal10_0Val):decimal(14,7)>
-- !query 373 output
1


-- !query 374
SELECT decimal14_7In(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 374 schema
struct<UDF(decimal30_15Val):decimal(14,7)>
-- !query 374 output
1


-- !query 375
SELECT decimal14_7In(binaryVal) FROM srcTestTable LIMIT 1
-- !query 375 schema
struct<>
-- !query 375 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1951.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1951.0 (TID 45973, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (binary) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 376
SELECT decimal14_7In(booleanVal) FROM srcTestTable LIMIT 1
-- !query 376 schema
struct<>
-- !query 376 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1952.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1952.0 (TID 45974, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (boolean) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 377
SELECT decimal14_7In(stringVal) FROM srcTestTable LIMIT 1
-- !query 377 schema
struct<>
-- !query 377 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1953.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1953.0 (TID 45975, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (string) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 378
SELECT decimal14_7In(dateVal) FROM srcTestTable LIMIT 1
-- !query 378 schema
struct<>
-- !query 378 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1954.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1954.0 (TID 45976, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (date) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 379
SELECT decimal14_7In(timestampVal) FROM srcTestTable LIMIT 1
-- !query 379 schema
struct<>
-- !query 379 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1955.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1955.0 (TID 45977, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (timestamp) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 380
SELECT decimal14_7In(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 380 schema
struct<>
-- !query 380 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1956.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1956.0 (TID 45978, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<int>) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 381
SELECT decimal14_7In(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 381 schema
struct<>
-- !query 381 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1957.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1957.0 (TID 45979, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (array<double>) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 382
SELECT decimal14_7In(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 382 schema
struct<>
-- !query 382 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1958.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1958.0 (TID 45980, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,int>) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 383
SELECT decimal14_7In(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 383 schema
struct<>
-- !query 383 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1959.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1959.0 (TID 45981, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (map<string,double>) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 384
SELECT decimal14_7In(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 384 schema
struct<>
-- !query 384 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1960.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1960.0 (TID 45982, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:int,d1:double>) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 385
SELECT decimal14_7In(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 385 schema
struct<>
-- !query 385 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1961.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1961.0 (TID 45983, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4913/1072001707: (struct<d0:string,d1:int>) => decimal(14,7))
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.math.BigDecimal
	... 17 more

Driver stacktrace:


-- !query 386
SELECT decimal14_7In(null)
-- !query 386 schema
struct<UDF(null):decimal(14,7)>
-- !query 386 output
NULL


-- !query 387
SELECT binaryIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 387 schema
struct<>
-- !query 387 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1963.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1963.0 (TID 45986, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (smallint) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Short cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 388
SELECT binaryIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 388 schema
struct<>
-- !query 388 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1964.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1964.0 (TID 45988, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (int) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 389
SELECT binaryIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 389 schema
struct<>
-- !query 389 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1965.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1965.0 (TID 45990, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (bigint) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 390
SELECT binaryIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 390 schema
struct<>
-- !query 390 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1966.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1966.0 (TID 45992, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (double) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 391
SELECT binaryIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 391 schema
struct<>
-- !query 391 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1967.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1967.0 (TID 45994, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (float) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 392
SELECT binaryIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 392 schema
struct<>
-- !query 392 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1968.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1968.0 (TID 45996, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (decimal(3,0)) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 393
SELECT binaryIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 393 schema
struct<>
-- !query 393 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1969.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1969.0 (TID 45998, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (decimal(5,0)) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 394
SELECT binaryIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 394 schema
struct<>
-- !query 394 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1970.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1970.0 (TID 46000, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (decimal(10,0)) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 395
SELECT binaryIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 395 schema
struct<>
-- !query 395 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1971.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1971.0 (TID 46002, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (decimal(10,2)) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 396
SELECT binaryIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 396 schema
struct<>
-- !query 396 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1972.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1972.0 (TID 46004, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (decimal(30,15)) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 397
SELECT binaryIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 397 schema
struct<>
-- !query 397 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 16


-- !query 398
SELECT binaryIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 398 schema
struct<>
-- !query 398 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1973.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1973.0 (TID 46005, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (boolean) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 399
SELECT binaryIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 399 schema
struct<>
-- !query 399 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1974.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1974.0 (TID 46006, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (string) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 400
SELECT binaryIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 400 schema
struct<>
-- !query 400 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1975.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1975.0 (TID 46007, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (date) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 401
SELECT binaryIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 401 schema
struct<>
-- !query 401 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1976.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1976.0 (TID 46008, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (timestamp) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 402
SELECT binaryIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 402 schema
struct<>
-- !query 402 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1977.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1977.0 (TID 46009, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (array<int>) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 403
SELECT binaryIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 403 schema
struct<>
-- !query 403 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1978.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1978.0 (TID 46010, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (array<double>) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 404
SELECT binaryIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 404 schema
struct<>
-- !query 404 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1979.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1979.0 (TID 46011, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (map<string,int>) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 405
SELECT binaryIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 405 schema
struct<>
-- !query 405 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1980.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1980.0 (TID 46012, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (map<string,double>) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 406
SELECT binaryIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 406 schema
struct<>
-- !query 406 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1981.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1981.0 (TID 46013, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (struct<d0:int,d1:double>) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 407
SELECT binaryIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 407 schema
struct<>
-- !query 407 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1982.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1982.0 (TID 46014, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4901/326119871: (struct<d0:string,d1:int>) => binary)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to [B
	... 17 more

Driver stacktrace:


-- !query 408
SELECT binaryIn(null)
-- !query 408 schema
struct<UDF:binaryIn(null):binary>
-- !query 408 output
NULL


-- !query 409
SELECT booleanIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 409 schema
struct<>
-- !query 409 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1984.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1984.0 (TID 46017, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (int) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 410
SELECT booleanIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 410 schema
struct<>
-- !query 410 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1985.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1985.0 (TID 46019, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (bigint) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 411
SELECT booleanIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 411 schema
struct<>
-- !query 411 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1986.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1986.0 (TID 46021, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (double) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 412
SELECT booleanIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 412 schema
struct<>
-- !query 412 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1987.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1987.0 (TID 46023, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (float) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 413
SELECT booleanIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 413 schema
struct<>
-- !query 413 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1988.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1988.0 (TID 46025, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (decimal(3,0)) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 414
SELECT booleanIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 414 schema
struct<>
-- !query 414 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1989.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1989.0 (TID 46027, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (decimal(5,0)) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 415
SELECT booleanIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 415 schema
struct<>
-- !query 415 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1990.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1990.0 (TID 46029, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (decimal(10,0)) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 416
SELECT booleanIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 416 schema
struct<>
-- !query 416 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1991.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1991.0 (TID 46031, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (decimal(10,2)) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 417
SELECT booleanIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 417 schema
struct<>
-- !query 417 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 1992.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1992.0 (TID 46033, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (decimal(30,15)) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 418
SELECT booleanIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 418 schema
struct<>
-- !query 418 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 17


-- !query 419
SELECT booleanIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 419 schema
struct<>
-- !query 419 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1993.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1993.0 (TID 46034, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (binary) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 420
SELECT booleanIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 420 schema
struct<>
-- !query 420 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1994.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1994.0 (TID 46035, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (string) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 421
SELECT booleanIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 421 schema
struct<>
-- !query 421 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1995.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1995.0 (TID 46036, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (date) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 422
SELECT booleanIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 422 schema
struct<>
-- !query 422 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1996.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1996.0 (TID 46037, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (timestamp) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 423
SELECT booleanIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 423 schema
struct<>
-- !query 423 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1997.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1997.0 (TID 46038, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (array<int>) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 424
SELECT booleanIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 424 schema
struct<>
-- !query 424 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1998.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1998.0 (TID 46039, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (array<double>) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 425
SELECT booleanIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 425 schema
struct<>
-- !query 425 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 1999.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1999.0 (TID 46040, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (map<string,int>) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 426
SELECT booleanIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 426 schema
struct<>
-- !query 426 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2000.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2000.0 (TID 46041, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (map<string,double>) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 427
SELECT booleanIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 427 schema
struct<>
-- !query 427 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2001.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2001.0 (TID 46042, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (struct<d0:int,d1:double>) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 428
SELECT booleanIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 428 schema
struct<>
-- !query 428 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2002.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2002.0 (TID 46043, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4903/1436203785: (struct<d0:string,d1:int>) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.Boolean
	at scala.runtime.BoxesRunTime.unboxToBoolean(BoxesRunTime.java:87)
	at org.apache.spark.sql.SQLQueryTestSuite.$anonfun$runQueries$8$adapted(SQLQueryTestSuite.scala:281)
	... 18 more

Driver stacktrace:


-- !query 429
SELECT booleanIn(null)
-- !query 429 schema
struct<UDF:booleanIn(null):boolean>
-- !query 429 output
NULL


-- !query 430
SELECT stringIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 430 schema
struct<>
-- !query 430 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2004.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2004.0 (TID 46046, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (smallint) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Short cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 431
SELECT stringIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 431 schema
struct<>
-- !query 431 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2005.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2005.0 (TID 46048, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (int) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 432
SELECT stringIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 432 schema
struct<>
-- !query 432 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2006.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2006.0 (TID 46050, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (bigint) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 433
SELECT stringIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 433 schema
struct<>
-- !query 433 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2007.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2007.0 (TID 46052, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (double) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 434
SELECT stringIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 434 schema
struct<>
-- !query 434 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2008.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2008.0 (TID 46054, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (float) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 435
SELECT stringIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 435 schema
struct<>
-- !query 435 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2009.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2009.0 (TID 46056, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (decimal(3,0)) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 436
SELECT stringIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 436 schema
struct<>
-- !query 436 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2010.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2010.0 (TID 46058, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (decimal(5,0)) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 437
SELECT stringIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 437 schema
struct<>
-- !query 437 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2011.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2011.0 (TID 46060, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (decimal(10,0)) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 438
SELECT stringIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 438 schema
struct<>
-- !query 438 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2012.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2012.0 (TID 46062, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (decimal(10,2)) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 439
SELECT stringIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 439 schema
struct<>
-- !query 439 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2013.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2013.0 (TID 46064, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (decimal(30,15)) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 440
SELECT stringIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 440 schema
struct<>
-- !query 440 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 16


-- !query 441
SELECT stringIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 441 schema
struct<>
-- !query 441 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2014.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2014.0 (TID 46065, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (binary) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 442
SELECT stringIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 442 schema
struct<>
-- !query 442 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2015.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2015.0 (TID 46066, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (boolean) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 443
SELECT stringIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 443 schema
struct<>
-- !query 443 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2016.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2016.0 (TID 46067, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (date) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 444
SELECT stringIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 444 schema
struct<>
-- !query 444 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2017.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2017.0 (TID 46068, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (timestamp) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 445
SELECT stringIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 445 schema
struct<>
-- !query 445 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2018.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2018.0 (TID 46069, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (array<int>) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 446
SELECT stringIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 446 schema
struct<>
-- !query 446 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2019.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2019.0 (TID 46070, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (array<double>) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 447
SELECT stringIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 447 schema
struct<>
-- !query 447 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2020.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2020.0 (TID 46071, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (map<string,int>) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 448
SELECT stringIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 448 schema
struct<>
-- !query 448 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2021.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2021.0 (TID 46072, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (map<string,double>) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 449
SELECT stringIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 449 schema
struct<>
-- !query 449 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2022.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2022.0 (TID 46073, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (struct<d0:int,d1:double>) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 450
SELECT stringIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 450 schema
struct<>
-- !query 450 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2023.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2023.0 (TID 46074, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4904/1898139836: (struct<d0:string,d1:int>) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.lang.String
	... 17 more

Driver stacktrace:


-- !query 451
SELECT stringIn(null)
-- !query 451 schema
struct<UDF:stringIn(null):string>
-- !query 451 output
NULL


-- !query 452
SELECT dateIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 452 schema
struct<>
-- !query 452 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2025.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2025.0 (TID 46077, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (smallint) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Short cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 453
SELECT dateIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 453 schema
struct<>
-- !query 453 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2026.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2026.0 (TID 46079, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (int) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 454
SELECT dateIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 454 schema
struct<>
-- !query 454 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2027.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2027.0 (TID 46081, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (bigint) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 455
SELECT dateIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 455 schema
struct<>
-- !query 455 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2028.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2028.0 (TID 46083, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (double) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 456
SELECT dateIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 456 schema
struct<>
-- !query 456 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2029.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2029.0 (TID 46085, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (float) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 457
SELECT dateIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 457 schema
struct<>
-- !query 457 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2030.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2030.0 (TID 46087, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (decimal(3,0)) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 458
SELECT dateIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 458 schema
struct<>
-- !query 458 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2031.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2031.0 (TID 46089, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (decimal(5,0)) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 459
SELECT dateIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 459 schema
struct<>
-- !query 459 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2032.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2032.0 (TID 46091, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (decimal(10,0)) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 460
SELECT dateIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 460 schema
struct<>
-- !query 460 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2033.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2033.0 (TID 46093, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (decimal(10,2)) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 461
SELECT dateIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 461 schema
struct<>
-- !query 461 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2034.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2034.0 (TID 46095, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (decimal(30,15)) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 462
SELECT dateIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 462 schema
struct<>
-- !query 462 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 14


-- !query 463
SELECT dateIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 463 schema
struct<>
-- !query 463 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2035.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2035.0 (TID 46096, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (binary) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 464
SELECT dateIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 464 schema
struct<>
-- !query 464 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2036.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2036.0 (TID 46097, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (boolean) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 465
SELECT dateIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 465 schema
struct<>
-- !query 465 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2037.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2037.0 (TID 46098, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (string) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 466
SELECT dateIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 466 schema
struct<>
-- !query 466 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2038.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2038.0 (TID 46099, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (timestamp) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 467
SELECT dateIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 467 schema
struct<>
-- !query 467 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2039.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2039.0 (TID 46100, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (array<int>) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 468
SELECT dateIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 468 schema
struct<>
-- !query 468 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2040.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2040.0 (TID 46101, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (array<double>) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 469
SELECT dateIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 469 schema
struct<>
-- !query 469 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2041.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2041.0 (TID 46102, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (map<string,int>) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 470
SELECT dateIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 470 schema
struct<>
-- !query 470 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2042.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2042.0 (TID 46103, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (map<string,double>) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 471
SELECT dateIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 471 schema
struct<>
-- !query 471 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2043.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2043.0 (TID 46104, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (struct<d0:int,d1:double>) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 472
SELECT dateIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 472 schema
struct<>
-- !query 472 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2044.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2044.0 (TID 46105, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4905/1310331060: (struct<d0:string,d1:int>) => date)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.sql.Date
	... 17 more

Driver stacktrace:


-- !query 473
SELECT dateIn(null)
-- !query 473 schema
struct<UDF:dateIn(null):date>
-- !query 473 output
NULL


-- !query 474
SELECT timestampIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 474 schema
struct<>
-- !query 474 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2046.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2046.0 (TID 46108, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (smallint) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Short cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 475
SELECT timestampIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 475 schema
struct<>
-- !query 475 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2047.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2047.0 (TID 46110, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (int) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 476
SELECT timestampIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 476 schema
struct<>
-- !query 476 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2048.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2048.0 (TID 46112, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (bigint) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 477
SELECT timestampIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 477 schema
struct<>
-- !query 477 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2049.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2049.0 (TID 46114, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (double) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 478
SELECT timestampIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 478 schema
struct<>
-- !query 478 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2050.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2050.0 (TID 46116, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (float) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 479
SELECT timestampIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 479 schema
struct<>
-- !query 479 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2051.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2051.0 (TID 46118, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (decimal(3,0)) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 480
SELECT timestampIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 480 schema
struct<>
-- !query 480 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2052.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2052.0 (TID 46120, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (decimal(5,0)) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 481
SELECT timestampIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 481 schema
struct<>
-- !query 481 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2053.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2053.0 (TID 46122, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (decimal(10,0)) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 482
SELECT timestampIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 482 schema
struct<>
-- !query 482 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2054.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2054.0 (TID 46124, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (decimal(10,2)) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 483
SELECT timestampIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 483 schema
struct<>
-- !query 483 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2055.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2055.0 (TID 46126, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (decimal(30,15)) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 484
SELECT timestampIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 484 schema
struct<>
-- !query 484 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 19


-- !query 485
SELECT timestampIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 485 schema
struct<>
-- !query 485 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2056.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2056.0 (TID 46127, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (binary) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 486
SELECT timestampIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 486 schema
struct<>
-- !query 486 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2057.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2057.0 (TID 46128, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (boolean) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 487
SELECT timestampIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 487 schema
struct<>
-- !query 487 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2058.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2058.0 (TID 46129, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (string) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 488
SELECT timestampIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 488 schema
struct<UDF:timestampIn(dateVal):timestamp>
-- !query 488 output
2018-07-06 00:00:00


-- !query 489
SELECT timestampIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 489 schema
struct<>
-- !query 489 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2060.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2060.0 (TID 46131, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (array<int>) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 490
SELECT timestampIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 490 schema
struct<>
-- !query 490 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2061.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2061.0 (TID 46132, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (array<double>) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 491
SELECT timestampIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 491 schema
struct<>
-- !query 491 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2062.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2062.0 (TID 46133, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (map<string,int>) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 492
SELECT timestampIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 492 schema
struct<>
-- !query 492 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2063.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2063.0 (TID 46134, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (map<string,double>) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 493
SELECT timestampIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 493 schema
struct<>
-- !query 493 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2064.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2064.0 (TID 46135, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (struct<d0:int,d1:double>) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 494
SELECT timestampIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 494 schema
struct<>
-- !query 494 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2065.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2065.0 (TID 46136, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4906/1034137001: (struct<d0:string,d1:int>) => timestamp)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to java.sql.Timestamp
	... 17 more

Driver stacktrace:


-- !query 495
SELECT timestampIn(null)
-- !query 495 schema
struct<UDF:timestampIn(null):timestamp>
-- !query 495 output
NULL


-- !query 496
SELECT arrayIntIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 496 schema
struct<>
-- !query 496 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2067.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2067.0 (TID 46139, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (smallint) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Short cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 497
SELECT arrayIntIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 497 schema
struct<>
-- !query 497 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2068.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2068.0 (TID 46141, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (int) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 498
SELECT arrayIntIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 498 schema
struct<>
-- !query 498 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2069.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2069.0 (TID 46143, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (bigint) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 499
SELECT arrayIntIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 499 schema
struct<>
-- !query 499 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2070.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2070.0 (TID 46145, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (double) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 500
SELECT arrayIntIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 500 schema
struct<>
-- !query 500 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2071.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2071.0 (TID 46147, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (float) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 501
SELECT arrayIntIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 501 schema
struct<>
-- !query 501 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2072.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2072.0 (TID 46149, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (decimal(3,0)) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 502
SELECT arrayIntIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 502 schema
struct<>
-- !query 502 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2073.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2073.0 (TID 46151, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (decimal(5,0)) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 503
SELECT arrayIntIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 503 schema
struct<>
-- !query 503 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2074.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2074.0 (TID 46153, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (decimal(10,0)) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 504
SELECT arrayIntIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 504 schema
struct<>
-- !query 504 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2075.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2075.0 (TID 46155, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (decimal(10,2)) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 505
SELECT arrayIntIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 505 schema
struct<>
-- !query 505 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2076.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2076.0 (TID 46157, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (decimal(30,15)) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 506
SELECT arrayIntIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 506 schema
struct<>
-- !query 506 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 18


-- !query 507
SELECT arrayIntIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 507 schema
struct<>
-- !query 507 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2077.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2077.0 (TID 46158, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (binary) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 508
SELECT arrayIntIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 508 schema
struct<>
-- !query 508 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2078.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2078.0 (TID 46159, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (boolean) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 509
SELECT arrayIntIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 509 schema
struct<>
-- !query 509 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2079.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2079.0 (TID 46160, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (string) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 510
SELECT arrayIntIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 510 schema
struct<>
-- !query 510 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2080.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2080.0 (TID 46161, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (date) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 511
SELECT arrayIntIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 511 schema
struct<>
-- !query 511 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2081.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2081.0 (TID 46162, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (timestamp) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 512
SELECT arrayIntIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 512 schema
struct<>
-- !query 512 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2082.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2082.0 (TID 46163, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (array<double>) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 513
SELECT arrayIntIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 513 schema
struct<>
-- !query 513 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2083.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2083.0 (TID 46164, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (map<string,int>) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 514
SELECT arrayIntIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 514 schema
struct<>
-- !query 514 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2084.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2084.0 (TID 46165, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (map<string,double>) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 515
SELECT arrayIntIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 515 schema
struct<>
-- !query 515 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2085.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2085.0 (TID 46166, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (struct<d0:int,d1:double>) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 516
SELECT arrayIntIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 516 schema
struct<>
-- !query 516 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2086.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2086.0 (TID 46167, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4907/551380942: (struct<d0:string,d1:int>) => array<int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to [I
	... 17 more

Driver stacktrace:


-- !query 517
SELECT arrayIntIn(null)
-- !query 517 schema
struct<UDF:arrayIntIn(null):array<int>>
-- !query 517 output
NULL


-- !query 518
SELECT arrayDoubleIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 518 schema
struct<>
-- !query 518 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2088.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2088.0 (TID 46170, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (smallint) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Short cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 519
SELECT arrayDoubleIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 519 schema
struct<>
-- !query 519 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2089.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2089.0 (TID 46172, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (int) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 520
SELECT arrayDoubleIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 520 schema
struct<>
-- !query 520 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2090.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2090.0 (TID 46174, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (bigint) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 521
SELECT arrayDoubleIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 521 schema
struct<>
-- !query 521 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2091.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2091.0 (TID 46176, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (double) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 522
SELECT arrayDoubleIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 522 schema
struct<>
-- !query 522 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2092.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2092.0 (TID 46178, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (float) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 523
SELECT arrayDoubleIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 523 schema
struct<>
-- !query 523 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2093.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2093.0 (TID 46180, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (decimal(3,0)) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 524
SELECT arrayDoubleIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 524 schema
struct<>
-- !query 524 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2094.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2094.0 (TID 46182, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (decimal(5,0)) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 525
SELECT arrayDoubleIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 525 schema
struct<>
-- !query 525 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2095.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2095.0 (TID 46184, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (decimal(10,0)) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 526
SELECT arrayDoubleIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 526 schema
struct<>
-- !query 526 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2096.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2096.0 (TID 46186, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (decimal(10,2)) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 527
SELECT arrayDoubleIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 527 schema
struct<>
-- !query 527 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2097.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2097.0 (TID 46188, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (decimal(30,15)) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 528
SELECT arrayDoubleIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 528 schema
struct<>
-- !query 528 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 21


-- !query 529
SELECT arrayDoubleIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 529 schema
struct<>
-- !query 529 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2098.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2098.0 (TID 46189, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (binary) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 530
SELECT arrayDoubleIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 530 schema
struct<>
-- !query 530 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2099.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2099.0 (TID 46190, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (boolean) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 531
SELECT arrayDoubleIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 531 schema
struct<>
-- !query 531 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2100.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2100.0 (TID 46191, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (string) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 532
SELECT arrayDoubleIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 532 schema
struct<>
-- !query 532 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2101.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2101.0 (TID 46192, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (date) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 533
SELECT arrayDoubleIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 533 schema
struct<>
-- !query 533 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2102.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2102.0 (TID 46193, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (timestamp) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 534
SELECT arrayDoubleIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 534 schema
struct<>
-- !query 534 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2103.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2103.0 (TID 46194, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (array<int>) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 535
SELECT arrayDoubleIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 535 schema
struct<>
-- !query 535 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2104.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2104.0 (TID 46195, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (map<string,int>) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 536
SELECT arrayDoubleIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 536 schema
struct<>
-- !query 536 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2105.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2105.0 (TID 46196, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (map<string,double>) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.immutable.Map$Map2 cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 537
SELECT arrayDoubleIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 537 schema
struct<>
-- !query 537 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2106.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2106.0 (TID 46197, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (struct<d0:int,d1:double>) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 538
SELECT arrayDoubleIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 538 schema
struct<>
-- !query 538 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2107.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2107.0 (TID 46198, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4908/1668981113: (struct<d0:string,d1:int>) => array<double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to [D
	... 17 more

Driver stacktrace:


-- !query 539
SELECT arrayDoubleIn(null)
-- !query 539 schema
struct<UDF:arrayDoubleIn(null):array<double>>
-- !query 539 output
NULL


-- !query 540
SELECT mapStringIntIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 540 schema
struct<>
-- !query 540 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2109.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2109.0 (TID 46201, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (smallint) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Short cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 541
SELECT mapStringIntIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 541 schema
struct<>
-- !query 541 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2110.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2110.0 (TID 46203, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (int) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 542
SELECT mapStringIntIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 542 schema
struct<>
-- !query 542 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2111.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2111.0 (TID 46205, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (bigint) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 543
SELECT mapStringIntIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 543 schema
struct<>
-- !query 543 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2112.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2112.0 (TID 46207, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (double) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 544
SELECT mapStringIntIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 544 schema
struct<>
-- !query 544 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2113.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2113.0 (TID 46209, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (float) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 545
SELECT mapStringIntIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 545 schema
struct<>
-- !query 545 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2114.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2114.0 (TID 46211, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (decimal(3,0)) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 546
SELECT mapStringIntIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 546 schema
struct<>
-- !query 546 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2115.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2115.0 (TID 46213, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (decimal(5,0)) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 547
SELECT mapStringIntIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 547 schema
struct<>
-- !query 547 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2116.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2116.0 (TID 46215, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (decimal(10,0)) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 548
SELECT mapStringIntIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 548 schema
struct<>
-- !query 548 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2117.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2117.0 (TID 46217, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (decimal(10,2)) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 549
SELECT mapStringIntIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 549 schema
struct<>
-- !query 549 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2118.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2118.0 (TID 46219, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (decimal(30,15)) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 550
SELECT mapStringIntIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 550 schema
struct<>
-- !query 550 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 22


-- !query 551
SELECT mapStringIntIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 551 schema
struct<>
-- !query 551 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2119.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2119.0 (TID 46220, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (binary) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 552
SELECT mapStringIntIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 552 schema
struct<>
-- !query 552 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2120.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2120.0 (TID 46221, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (boolean) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 553
SELECT mapStringIntIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 553 schema
struct<>
-- !query 553 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2121.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2121.0 (TID 46222, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (string) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 554
SELECT mapStringIntIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 554 schema
struct<>
-- !query 554 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2122.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2122.0 (TID 46223, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (date) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 555
SELECT mapStringIntIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 555 schema
struct<>
-- !query 555 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2123.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2123.0 (TID 46224, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (timestamp) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 556
SELECT mapStringIntIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 556 schema
struct<>
-- !query 556 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2124.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2124.0 (TID 46225, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (array<int>) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 557
SELECT mapStringIntIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 557 schema
struct<>
-- !query 557 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2125.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2125.0 (TID 46226, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (array<double>) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 558
SELECT mapStringIntIn(mapStringDoubleVal) FROM srcTestTable LIMIT 1
-- !query 558 schema
struct<>
-- !query 558 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2126.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2126.0 (TID 46227, localhost, executor driver): java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:103)
	at org.apache.spark.sql.catalyst.util.GenericArrayData.getInt(GenericArrayData.scala:70)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:


-- !query 559
SELECT mapStringIntIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 559 schema
struct<>
-- !query 559 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2127.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2127.0 (TID 46228, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (struct<d0:int,d1:double>) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 560
SELECT mapStringIntIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 560 schema
struct<>
-- !query 560 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2128.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2128.0 (TID 46229, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4909/981576771: (struct<d0:string,d1:int>) => map<string,int>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 561
SELECT mapStringIntIn(null)
-- !query 561 schema
struct<UDF:mapStringIntIn(null):map<string,int>>
-- !query 561 output
NULL


-- !query 562
SELECT mapStringDoubleIn(shortVal) FROM srcTestTable WHERE shortVal = 1
-- !query 562 schema
struct<>
-- !query 562 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2130.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2130.0 (TID 46232, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (smallint) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Short cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 563
SELECT mapStringDoubleIn(intVal) FROM srcTestTable WHERE intVal = 1
-- !query 563 schema
struct<>
-- !query 563 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2131.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2131.0 (TID 46234, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (int) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 564
SELECT mapStringDoubleIn(longVal) FROM srcTestTable WHERE longVal = 1
-- !query 564 schema
struct<>
-- !query 564 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2132.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2132.0 (TID 46236, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (bigint) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 565
SELECT mapStringDoubleIn(doubleVal) FROM srcTestTable WHERE doubleVal < 1.1
-- !query 565 schema
struct<>
-- !query 565 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2133.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2133.0 (TID 46238, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (double) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Double cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 566
SELECT mapStringDoubleIn(floatVal) FROM srcTestTable WHERE floatVal< 1.1
-- !query 566 schema
struct<>
-- !query 566 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2134.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2134.0 (TID 46240, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (float) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Float cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 567
SELECT mapStringDoubleIn(decimal3_0Val) FROM srcTestTable WHERE decimal3_0Val = 1
-- !query 567 schema
struct<>
-- !query 567 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2135.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2135.0 (TID 46242, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (decimal(3,0)) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 568
SELECT mapStringDoubleIn(decimal5_0Val) FROM srcTestTable WHERE decimal5_0Val = 1
-- !query 568 schema
struct<>
-- !query 568 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2136.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2136.0 (TID 46244, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (decimal(5,0)) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 569
SELECT mapStringDoubleIn(decimal10_0Val) FROM srcTestTable WHERE decimal10_0Val = 1
-- !query 569 schema
struct<>
-- !query 569 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2137.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2137.0 (TID 46246, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (decimal(10,0)) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 570
SELECT mapStringDoubleIn(decimal10_2Val) FROM srcTestTable WHERE decimal10_2Val = 1
-- !query 570 schema
struct<>
-- !query 570 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2138.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2138.0 (TID 46248, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (decimal(10,2)) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 571
SELECT mapStringDoubleIn(decimal30_15Val) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 571 schema
struct<>
-- !query 571 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 1 in stage 2139.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2139.0 (TID 46250, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (decimal(30,15)) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.math.BigDecimal cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 572
SELECT mapStringDoubleIn(decimal14_7In) FROM srcTestTable WHERE decimal30_15Val = 1
-- !query 572 schema
struct<>
-- !query 572 output
org.apache.spark.sql.AnalysisException
cannot resolve '`decimal14_7In`' given input columns: [default.srctesttable.arrayDoubleVal, default.srctesttable.arrayIntVal, default.srctesttable.binaryVal, default.srctesttable.booleanVal, default.srctesttable.byteVal, default.srctesttable.dateVal, default.srctesttable.decimal10_0Val, default.srctesttable.decimal10_2Val, default.srctesttable.decimal14_7Val, default.srctesttable.decimal20_0Val, default.srctesttable.decimal30_15Val, default.srctesttable.decimal3_0Val, default.srctesttable.decimal5_0Val, default.srctesttable.doubleVal, default.srctesttable.floatVal, default.srctesttable.intVal, default.srctesttable.longVal, default.srctesttable.mapStringDoubleVal, default.srctesttable.mapStringIntVal, default.srctesttable.shortVal, default.srctesttable.stringVal, default.srctesttable.structIntDoubleVal, default.srctesttable.structStringIntVal, default.srctesttable.timestampVal]; line 1 pos 25


-- !query 573
SELECT mapStringDoubleIn(binaryVal) FROM srcTestTable LIMIT 1
-- !query 573 schema
struct<>
-- !query 573 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2140.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2140.0 (TID 46251, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (binary) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: [B cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 574
SELECT mapStringDoubleIn(booleanVal) FROM srcTestTable LIMIT 1
-- !query 574 schema
struct<>
-- !query 574 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2141.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2141.0 (TID 46252, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (boolean) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.Boolean cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 575
SELECT mapStringDoubleIn(stringVal) FROM srcTestTable LIMIT 1
-- !query 575 schema
struct<>
-- !query 575 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2142.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2142.0 (TID 46253, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (string) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 576
SELECT mapStringDoubleIn(dateVal) FROM srcTestTable LIMIT 1
-- !query 576 schema
struct<>
-- !query 576 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2143.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2143.0 (TID 46254, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (date) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Date cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 577
SELECT mapStringDoubleIn(timestampVal) FROM srcTestTable LIMIT 1
-- !query 577 schema
struct<>
-- !query 577 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2144.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2144.0 (TID 46255, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (timestamp) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 578
SELECT mapStringDoubleIn(arrayIntVal) FROM srcTestTable LIMIT 1
-- !query 578 schema
struct<>
-- !query 578 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2145.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2145.0 (TID 46256, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (array<int>) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 579
SELECT mapStringDoubleIn(arrayDoubleVal) FROM srcTestTable LIMIT 1
-- !query 579 schema
struct<>
-- !query 579 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2146.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2146.0 (TID 46257, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (array<double>) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: scala.collection.mutable.WrappedArray$ofRef cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 580
SELECT mapStringDoubleIn(mapStringIntVal) FROM srcTestTable LIMIT 1
-- !query 580 schema
struct<>
-- !query 580 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2147.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2147.0 (TID 46258, localhost, executor driver): java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:116)
	at org.apache.spark.sql.catalyst.util.GenericArrayData.getDouble(GenericArrayData.scala:73)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:


-- !query 581
SELECT mapStringDoubleIn(structIntDoubleVal) FROM srcTestTable LIMIT 1
-- !query 581 schema
struct<>
-- !query 581 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2148.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2148.0 (TID 46259, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (struct<d0:int,d1:double>) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 582
SELECT mapStringDoubleIn(structStringIntVal) FROM srcTestTable LIMIT 1
-- !query 582 schema
struct<>
-- !query 582 output
org.apache.spark.SparkException
Job aborted due to stage failure: Task 0 in stage 2149.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2149.0 (TID 46260, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(SQLQueryTestSuite$$Lambda$4911/989065751: (struct<d0:string,d1:int>) => map<string,double>)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:735)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:328)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:852)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:852)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:126)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:426)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:429)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema cannot be cast to scala.collection.immutable.Map
	... 17 more

Driver stacktrace:


-- !query 583
SELECT mapStringDoubleIn(null)
-- !query 583 schema
struct<UDF:mapStringDoubleIn(null):map<string,double>>
-- !query 583 output
NULL


-- !query 584
DROP TABLE srcTestTable
-- !query 584 schema
struct<>
-- !query 584 output

